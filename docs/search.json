[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Weather Shocks",
    "section": "",
    "text": "Index\nThis ebook provides some notebooks to help adapting the methodology of our paper Weather Shock (Gallic and Vermandel (2020)) to new contexts or datasets.\nThe notebooks are in construction, this page will be filled soon.\n\n\n\n\nGallic, Ewen, and Gauthier Vermandel. 2020. “Weather Shocks.” European Economic Review 124 (May): 103409. https://doi.org/10.1016/j.euroecorev.2020.103409.",
    "crumbs": [
      "Index"
    ]
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "1  Useful Functions",
    "section": "",
    "text": "1.1 Functions fro Graphs\nThroughout the analysis, we will need a few user-defined functions. While the functions specific to a part of the analysis are presented in the corresponding chapter, some functions are needed in multiple parts of this project. We define those here. These functions are contained in the ../scripts/functions/utils.R file.\nWe define theme functions for the plots.\nThe main theme for the plots:\n#' Theme for ggplot2\n#'\n#' @param ... arguments passed to the theme function\n#' @export\n#' @importFrom ggplot2 element_rect element_text element_blank element_line unit\n#'   rel\ntheme_paper &lt;- function (...) {\n  theme(\n    text = element_text(family = \"Times New Roman\"),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    panel.border = element_rect(fill = NA, colour = \"grey50\", linewidth = 1),\n    axis.text = element_text(),\n    legend.text = element_text(size = rel(1.1)),\n    legend.title = element_text(size = rel(1.1)),\n    legend.background = element_rect(fill = \"transparent\", color = NULL),\n    legend.position = \"bottom\",\n    legend.direction = \"horizontal\",\n    legend.box = \"vertical\",\n    legend.key = element_blank(),\n    panel.spacing = unit(1, \"lines\"),\n    panel.grid.major = element_line(colour = \"grey90\"),\n    panel.grid.minor = element_blank(),\n    plot.title = element_text(hjust = 0, size = rel(1.3), face = \"bold\"),\n    plot.title.position = \"plot\",\n    plot.margin = unit(c(1, 1, 1, 1), \"lines\"),\n    strip.background = element_rect(fill = NA, colour = NA),\n    strip.text = element_text(size = rel(1.1))\n  )\n}\nA function for maps:\n#' Theme for maps with ggplot2\n#'\n#' @param ... arguments passed to the theme function\n#' @export\n#' @importFrom ggplot2 element_rect element_text element_blank element_line unit\n#'   rel\ntheme_map_paper &lt;- function(...) {\n  theme(\n    text = element_text(family = \"Times New Roman\"),\n    plot.background = element_rect(fill = \"transparent\", color = NA),\n    panel.background = element_rect(fill = \"transparent\", color = NA),\n    panel.border = element_blank(),\n    axis.title = element_blank(),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(), axis.line = element_blank(),\n    plot.title.position = \"plot\",\n    legend.text = element_text(size = rel(1.2)),\n    legend.title = element_text(size = rel(1.2)),\n    legend.background = element_rect(fill=\"transparent\", color = NULL),\n    legend.key = element_blank(),\n    legend.key.height   = unit(2, \"line\"),\n    legend.key.width    = unit(1.5, \"line\"),\n    strip.background = element_rect(fill = NA),\n    panel.spacing = unit(1, \"lines\"),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    plot.margin = unit(c(1, 1, 1, 1), \"lines\"),\n    strip.text = element_text(size = rel(1.2))\n  )\n}\nTo transform the graphs into tikz pictures, we use the following function:\n#' Save a ggplot2 plot as PDF, using LaTeX tikz\n#'\n#' @param plot ggplot2 object\n#' @param path_to_latex path to LaTeX engine (Defaults to\n#'   `/Library/TeX/texbin/`)\n#' @param interpreter by default, use pdflatex (`pdflatex`)\n#' @param path path to the destination folder\n#' @param filename file name (without the extension)\n#' @param keep_tex should the tex file be kept after compilation? Defaults to\n#'   `FALSE`\n#' @param width width in inches (default to 15)\n#' @param height height in inches (default to 15)\n#' @param verbose A logical value indicating whether diagnostic messages are\n#'   printed when measuring dimensions of strings. Defaults to `FALSE`\n#' @param ignore.stdout a logical (not NA) indicating whether messages written\n#'   to ‘stdout’  should be ignored. Defaults to `TRUE`\n#'\n#' @export\n#' @importFrom tikzDevice tikz\n#' @importFrom grDevices dev.off\nggplot2_to_pdf &lt;- function(plot,\n                           path_to_latex = \"/Library/TeX/texbin/\",\n                           interpreter = \"pdflatex\",\n                           path = \"./\",\n                           filename,\n                           keep_tex = FALSE,\n                           width = 15,\n                           height = 15,\n                           verbose = FALSE,\n                           ignore.stdout = TRUE){\n    content &lt;- paste0(\n      \"\\\\documentclass{standalone}\n      \\\\usepackage{amssymb}\n      %\\\\usepackage{newtxtext,newtxmath}\n      \\\\usepackage{times,mathpazo}\n      \\\\usepackage{pgfplots}\n      \\\\usetikzlibrary{pgfplots.groupplots}\n      \\\\definecolor{mygrey2}{RGB}{127,127,127}\n      \\\\definecolor{deepblue}{RGB}{0,129,188}\n      \\\\definecolor{deepgreen}{RGB}{0,157,87}\n      \\\\definecolor{deepred}{RGB}{238,50,78}\n      \\\\begin{document}\n\n      \\\\input{\",\n      path, filename,\n      \"_content.tex}\n\n      \\\\end{document}\"\n    )\n\n    # The file which will import the graph in tex format\n    fileConn &lt;- file(paste0(path, filename, \".tex\"))\n    writeLines(content, fileConn)\n    close(fileConn)\n\n    # Export graph to tex\n    tikz(file = paste0(\n      path,\n      filename, \"_content.tex\"),\n      width = width,\n      height = height,\n      verbose = verbose\n    )\n    print(plot)\n    dev.off()\n\n    # Move the scale from ggplot, if any\n    name_scale &lt;- paste0(filename, \"_content_ras1.png\")\n    scale_exists &lt;- file.exists(name_scale)\n    if (scale_exists & ! path %in% c(\".\", \"./\", \"/\")) {\n      system(paste0(\"mv \", name_scale, \" \", path))\n    }\n\n    # Process tex file to get the PDF\n    system(\n      paste0(\n        path_to_latex,\n        interpreter, \" -shell-escape -synctex=1 -interaction=nonstopmode  \",\n        path,\n        filename, \".tex\"),\n      ignore.stdout = TRUE\n    )\n    if(!path %in%  c(\".\", \"./\", \"/\")) system(paste0(\"mv \", filename, \".pdf \", path))\n    system(paste0(\"rm \", filename, \".aux\"))\n    system(paste0(\"rm \", filename, \".log\"))\n    system(paste0(\"rm \", filename, \".synctex.gz\"))\n    if (!keep_tex) {\n      system(paste0(\"rm \", path, filename, \".tex\"))\n      system(paste0(\"rm \", path, filename, \"_content.tex\"))\n    }\n    if (scale_exists) system(paste0(\"rm \", path, \"/\", name_scale))\n  }",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Useful Functions</span>"
    ]
  },
  {
    "objectID": "data-maps.html",
    "href": "data-maps.html",
    "title": "2  Maps",
    "section": "",
    "text": "2.1 Helper Functions\nWe need the following packages:\nWe have shown in Chapter 1 some theme functions for plots. These functions are written in an R script that we can load to have access to those functions.\nWe need to get the boundaries of New Zealand. We define a tibble with the names of the country as well as its corresponding ISO-3 classification.\nWe add a column with the name (this will be used to name the folder in which the data will be saved).\nLet us save this for later use:\nWe need three functions for the maps:\nThe first function, download_map():\n#' Download GADM shapefile (version 4.1)\n#' \n#' @param country_name name of the country\n#' @param country_code ISO-3 country code\n#' @param country_name_clear name of the country withour space or \\'\ndownload_map &lt;- function(country_name, country_code, country_name_clear) {\n  file_name &lt;- str_c(\"gadm41_\", country_code, \"_shp.zip\")\n  url &lt;- str_c(\"https://geodata.ucdavis.edu/gadm/gadm4.1/shp/\", file_name)\n  dest_file &lt;- str_c(\n    \"../data/Maps/GADM-4.1/\", str_replace_all(country_name_clear, \" \", \"-\"), \"/\",\n    file_name\n    )\n  download.file(url = url, destfile = dest_file)\n}\nAnd the second one, import_map() which imports the maps data from the shapefile, extracts the 3 layers corresponding to administrative units (if available) and then saves them in the country’s directory.\n#' Imports map data downloaded from GADM, extracts layers and saves the result\n#' \n#' @param country_name name of the country\n#' @param country_code ISO-3 country code\n#' @param country_name_clear name of the country withour space or \\'\n#' \n#' @returns the `NULL` object\nimport_map &lt;- function(country_name, country_code, country_name_clear) {\n  out_directory &lt;- tempfile()\n  dir &lt;- \"../data/Maps/GADM-4.1/\"\n  file &lt;- str_c(dir, country_name_clear, \"/gadm41_\", country_code, \"_shp.zip\")\n  layer_0 &lt;- str_c(\"gadm41_\", country_code, \"_0\")\n  layer_1 &lt;- str_c(\"gadm41_\", country_code, \"_1\")\n  layer_2 &lt;- str_c(\"gadm41_\", country_code, \"_2\")\n\n  unzip(file, exdir = out_directory)\n  map_level_0 &lt;- st_read(dsn = out_directory, layer = layer_0, quiet = TRUE)\n  map_level_1 &lt;- st_read(dsn = out_directory, layer = layer_1, quiet = TRUE)\n  map_level_2 &lt;- try(st_read(dsn = out_directory, layer = layer_2, quiet = TRUE))\n  if (inherits(map_level_2, \"try-error\")) map_level_2 &lt;- NULL\n  res &lt;- list(\n    map_level_0 = map_level_0,\n    map_level_1 = map_level_1,\n    map_level_2 = map_level_2\n  )\n  res_name &lt;- str_to_lower(str_c(country_code, \"_maps\"))\n  assign(res_name, res)\n  eval(parse(\n    text = paste0(\n      \"save('\", res_name,\n      \"', file = '\", dir, \"/\", country_name_clear, \"/\", res_name, \".RData')\")\n  ))\n  NULL\n}\n#' Load the layers of a country's map\n#' \n#' @param country_name name of the country\n#' @param tb_countries tibble with the names of countries (`country_code`),\n#' the corresponding ISO-3 classification (`country_code`)\nload_country_map &lt;- function(country_name, tb_countries) {\n  current_tb_country &lt;- tb_countries |&gt; filter(country_name == !!country_name)\n  country_code &lt;- current_tb_country$country_code\n  country_name_clear &lt;- current_tb_country$country_name_clear\n  current_folder &lt;- str_c(\"../data/Maps/GADM-4.1/\", country_name_clear)\n  output_name &lt;- str_c(\n    current_folder, \"/\",\n    str_to_lower(str_c(country_code, \"_maps\")),\n    \".RData\"\n  )\n  load(output_name)\n  object_name &lt;- str_c(str_to_lower(country_code), \"_maps\")\n  get(object_name)\n}",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#helper-functions",
    "href": "data-maps.html#helper-functions",
    "title": "2  Maps",
    "section": "",
    "text": "one to download the shapefiles from the GADM website,\nanother one to extract relevant information (administrative units of level 1 to 3),\nand a third one to load the data in R.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#download-data",
    "href": "data-maps.html#download-data",
    "title": "2  Maps",
    "section": "2.2 Download Data",
    "text": "2.2 Download Data\nLet us loop over the countries (just New Zealand here) to download the shapefiles.\n\ncli::cli_progress_bar(\"Downloading SHP files\", total = nrow(tb_countries))\nfor (i in 1:nrow(tb_countries)) {\n  current_country_name &lt;- tb_countries$country_name[i]\n  current_country_code &lt;- tb_countries$country_code[i]\n  current_country_name_clear &lt;- tb_countries$country_name_clear[i]\n  \n  current_folder &lt;- str_c(\"../data/Maps/GADM-4.1/\", current_country_name_clear)\n  # If data not already downloaded:\n  # Create folder and download data\n  if (!dir.exists(current_folder)) {\n    dir.create(current_folder, recursive = TRUE)\n    download_map(\n      country_name = current_country_name,\n      country_code = current_country_code,\n      country_name_clear = current_country_name_clear\n    )\n  }\n  cli::cli_progress_update()\n}\ncli::cli_progress_done()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#import-shapefiles",
    "href": "data-maps.html#import-shapefiles",
    "title": "2  Maps",
    "section": "2.3 Import Shapefiles",
    "text": "2.3 Import Shapefiles\nNow that the shapefiles were downloaded, we can extract the information from them and save the extracted information into RData files that can be loaded when needed.\nLet us loop again on the countries. We can do it in a parallel way, to fasten the process.\n\nlibrary(future)\nnb_cores &lt;- future::availableCores()-1\nplan(multisession, workers = nb_cores)\nprogressr::with_progress({\n  p &lt;- progressr::progressor(steps = nrow(tb_countries))\n  tmp &lt;- furrr::future_map(\n    .x = 1:nrow(tb_countries),#looping on the row numbers\n    .f = ~{\n      current_country_name &lt;- tb_countries$country_name[.x]\n      current_country_code &lt;- tb_countries$country_code[.x]\n      current_country_name_clear &lt;- tb_countries$country_name_clear[.x]\n      # Check if the file already exists\n      current_folder &lt;- str_c(\"../data/Maps/GADM-4.1/\", current_country_name_clear)\n      output_name &lt;- str_c(\n        current_folder, \"/\",\n        str_to_lower(str_c(current_country_code, \"_maps\")),\n        \".RData\"\n      )\n      if (!file.exists(output_name)) {\n        # If it does not\n        # Import the data and save the extracted information\n      import_map(\n        country_name = tb_countries$country_name[.x],\n        country_code = tb_countries$country_code[.x],\n        country_name_clear = tb_countries$country_name_clear[.x]\n      )\n      }\n      p()\n      NULL\n    }\n  )\n})",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#load-extracted-maps",
    "href": "data-maps.html#load-extracted-maps",
    "title": "2  Maps",
    "section": "2.4 Load Extracted Maps",
    "text": "2.4 Load Extracted Maps\nAll the maps of interest for the study have been downloaded and the information we are looking for has been extracted. We can easily load the data now. Let us create a list with all the maps from all the countries of interest.\n\nall_maps &lt;- \n  map(\n    .x = tb_countries$country_name,\n    .f = ~load_country_map(country_name = .x, tb_countries = tb_countries)\n  )\nnames(all_maps) &lt;- tb_countries$country_code\n\nThe borders are too precise for what we need to do. Let us simplify the objects (this will allow us to have lighter graph files without loosing too much detail).\n\n2.4.1 Level 0 (borders)\nLevel 0 maps corresponds to the countries boundaries.\n\n# Simplification\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nmaps_level_0 &lt;- map(all_maps, \"map_level_0\")\nmaps_level_0 &lt;- map(\n  maps_level_0,\n  ~st_simplify(.x, dTolerance = 0.01)\n)\n\nWe save this file for later use:\n\nsave(maps_level_0, file = \"../data/Maps/GADM-4.1/maps_level_0.RData\")\n\n\nmaps_level_0_all &lt;- do.call(\"rbind\", maps_level_0)\nmaps_level_0_plot &lt;- map(\n  .x = tb_countries$country_name,\n  .f = function(x) {\n    p &lt;- ggplot(\n      data = maps_level_0_all |&gt;\n        filter(COUNTRY == x)\n    ) +\n      geom_sf()\n    if (x %in% c(\"Fiji\", \"New Zealand\"))\n      p &lt;- p + coord_sf(crs = \"+init=epsg:3460\")\n    p + theme_map_paper()\n    }\n)\n\n\ncowplot::plot_grid(\n  plotlist = c(\n    map(\n      .x = maps_level_0_plot,\n      .f = ~.x + theme(legend.position = 'none')\n    )\n  ),\n  labels = tb_countries$country_name_short,\n  label_size = 10\n)\n\nWarning in CPL_crs_from_input(x): GDAL Message 1: +init=epsg:XXXX syntax is\ndeprecated. It might return a CRS with a non-EPSG compliant axis order.\n\n\n\n\n\nFigure 2.1: Map of New Zealand\n\n\n\n\n\n\n\n\n\n\n2.4.2 Level 1\nLet us consider level 1.\n\n# Simplification\nsf_use_s2(FALSE)\nmaps_level_1 &lt;- map(all_maps, \"map_level_1\")\nmaps_level_1 &lt;- map(\n  maps_level_1,\n  ~st_simplify(.x, dTolerance = 0.01)\n)\n\nSaving the object:\n\nsave(maps_level_1, file = \"../data/Maps/GADM-4.1/maps_level_1.RData\")\n\n\nmaps_level_1_all &lt;- do.call(\"rbind\", maps_level_1)\nmaps_level_1_plot &lt;- map(\n  .x = tb_countries$country_name,\n  .f = function(x) {\n    p &lt;- ggplot(\n      data = maps_level_1_all |&gt;\n        filter(COUNTRY == x)\n    ) +\n      geom_sf(mapping = aes(group = ISO_1))\n    if (x %in% c(\"Fiji\", \"New Zealand\")) \n      p &lt;- p + coord_sf(crs = \"+init=epsg:3460\")\n    p + theme_map_paper()\n  }\n)\n\n\ncowplot::plot_grid(\n  plotlist = c(\n    map(\n      .x = maps_level_1_plot,\n      .f = ~.x + theme(legend.position = 'none')\n    )\n  ),\n  labels = tb_countries$country_name_short,\n  label_size = 10\n)\n\n\n\n\nFigure 2.2: Map of New Zealand (Regions level 1)\n\n\n\n\n\n\n\n\n\n\n2.4.3 Level 2\nAnd lastly, we consider level 2.\n\nmaps_level_2 &lt;- map(all_maps, \"map_level_2\")\nkeep &lt;- map_lgl(maps_level_2, ~!is.null(.x))\nmaps_level_2 &lt;- map(\n  maps_level_2[keep],\n  ~st_simplify(.x, dTolerance = 0.01)\n)\n\nSaving file:\n\nsave(maps_level_2, file = \"../data/Maps/GADM-4.1/maps_level_2.RData\")\n\n\nmaps_level_2_all &lt;- do.call(\"rbind\", maps_level_2)\nmaps_level_2_plot &lt;- map(\n  .x = tb_countries$country_name,\n  .f = function(x) {\n    p &lt;- ggplot(\n      data = maps_level_2_all |&gt;\n        filter(COUNTRY == x)\n    ) +\n      geom_sf(mapping = aes(group = GID_2))\n    if (x %in% c(\"Fiji\", \"New Zealand\"))\n      p &lt;- p + coord_sf(crs = \"+init=epsg:3460\")\n    p + theme_map_paper()\n  }\n)\n\n\ncowplot::plot_grid(\n  plotlist = c(\n    map(\n      .x = maps_level_2_plot,\n      .f = ~.x + theme(legend.position = 'none')\n    )\n  ),\n  labels = tb_countries$country_name,\n  label_size = 10\n)\n\n\n\n\nFigure 2.3: Map of New Zealand (Regions level 2)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#bounding-boxes",
    "href": "data-maps.html#bounding-boxes",
    "title": "2  Maps",
    "section": "2.5 Bounding boxes",
    "text": "2.5 Bounding boxes\nWhen we download gridded weather data, we will focus on the parts of the grid that correspond to New Zealand. Let us get the bounding box of the country to make this task easier. We show the R code to do so here, but we will evaluate it again in [Chapter @-sec-weather-data].\n\nbboxes &lt;- map(maps_level_0, st_bbox)\n\n\n\n\n\n\n\nNote\n\n\n\nIf you re-use this code for the Fiji Islands or New Zealand, be careful. The bounding box needs to be recreated. Otherwise, it is too large, as the coordinates of this country is not convenient to work with using this map projection.\n\n\n\n\nCode\nmaps_level_0_plot_bbox &lt;- map(\n  .x = tb_countries$country_name,\n  .f = function(x) {\n    current_country_code &lt;- tb_countries |&gt; \n      filter(country_name == x) |&gt; pull(\"country_code\")\n    bbox &lt;- bboxes[[current_country_code]]\n    p &lt;- ggplot(\n      data = maps_level_0_all |&gt;\n        filter(COUNTRY == x)\n    ) +\n      geom_sf() +\n      annotate(\n        geom = \"rect\", \n        xmin = bbox$xmin, xmax = bbox$xmax, \n        ymin = bbox$ymin, ymax = bbox$ymax,\n        fill = \"#56B4E9\", alpha = .1, linetype = \"dashed\", colour = \"black\"\n      )\n    if (x == \"Fiji\") p &lt;- p + coord_sf(crs = \"+init=epsg:3460\")\n    p + theme_map_paper()\n  }\n)\ncowplot::plot_grid(\n  plotlist = c(\n    map(\n      .x = maps_level_0_plot_bbox,\n      .f = ~.x + theme(legend.position = 'none')\n    )\n  ),\n  labels = tb_countries$country_name_short,\n  label_size = 10\n)\n\n\n\n\n\nFigure 2.4: Map of New Zealand, showing the initial extracted bounding box (blue shaded area delimited with dashed lines).\n\n\n\n\n\n\n\n\nFor simplicity, we will exclude the Chatham island and the Auckland Islands.\nWe define the new values for the bounding box:\n\nbboxes$NZL[[\"xmin\"]] &lt;- 167\nbboxes$NZL[[\"xmax\"]] &lt;- 179\nbboxes$NZL[[\"ymin\"]] &lt;- -48\nbboxes$NZL[[\"ymax\"]] &lt;- -34\n\n\n\nCode\nbbox &lt;- bboxes[[\"NZL\"]]\nbbox_sf &lt;- st_as_sfc(st_bbox(bbox), crs = 4326) |&gt; \n  st_transform(3460)\nbbox_trans &lt;- st_bbox(bbox_sf)\n\nggplot(\n  data = maps_level_0_all |&gt;\n    filter(COUNTRY == \"New Zealand\")\n) +\n  geom_sf() +\n  annotate(\n    geom = \"rect\", \n    xmin = bbox_trans$xmin, xmax = bbox_trans$xmax, \n    ymin = bbox_trans$ymin, ymax = bbox_trans$ymax,\n    fill = \"#56B4E9\", alpha = .1, linetype = \"dashed\", colour = \"black\"\n  ) +\n  coord_sf(crs = \"+init=epsg:3460\")\n\n\n\n\n\nFigure 2.5: Map of New Zealand, showing the extracted bounding box (blue shaded area delimited with dashed lines).",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-maps.html#global-look",
    "href": "data-maps.html#global-look",
    "title": "2  Maps",
    "section": "2.6 Global Look",
    "text": "2.6 Global Look\nLet us have a global look.\nWe first load a world map from the {maps} package.\n\nworld &lt;- sf::st_as_sf(maps::map('world', plot = FALSE, fill = TRUE)) |&gt; \n  mutate(ID = ifelse(ID == \"Ivory Coast\", \"Côte d'Ivoire\", ID))\n\n\n\nCode\nggplot(\n  data = world |&gt; \n    mutate(nz = ID %in% tb_countries$country_name),\n  mapping = aes(fill = nz)\n) +\n  geom_sf() +\n  scale_fill_manual(\n    NULL,\n    values = c(\"TRUE\" = \"#009E73\", \"FALSE\" = \"lightgray\"),\n    guide = \"none\"\n  ) +\n  theme_map_paper()\n\n\n\n\n\nFigure 2.6: New Zealand (in Green).",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Maps</span>"
    ]
  },
  {
    "objectID": "data-weather-download.html",
    "href": "data-weather-download.html",
    "title": "3  Weather Data: Download",
    "section": "",
    "text": "3.1 Download and Extract Data\nThis chapter is compiled to be rendered as an HTML page. To avoid downloading the data everytime a compilation needs to be done, we define a variable, download_data, that is set to FALSE. Set the variable to TRUE if you want to download the data while evaluating the codes on your own.\nA few packages are needed:\nWe have shown in Chapter 1 some theme functions for plots. These functions are written in an R script that we can load to have access to those functions.\nWe extracted countries’ boundaries in Chapter 2.\nWe focus on the following countries defined in Chapter 2\nLet us import the raw grid data into R. We proceed in three steps:\nThe function from the second step is the following:\n#' From the NetCDF file, extract the daily temperatures (min or max) of the\n#' grid. Creates a tibble in which each row corresponds to a cell of the grid\n#' with the following columns:\n#'  - longitude: longitude of the centroid of the cell\n#'  - latitude: latitude of the centroid of the cell\n#'  - grid_id: country code x numerical identifier\n#'  - intersect_area: area of the intersection between the country and the\n#'    cell\n#'  - country code: ISO-3 country code\n#'  - geometry: the coordinates of the cell\n#'  - value: total daily precipitation\n#'  - date: YYYY-MM-DD date\n#' The tibble is saved in `../data/Weather/CPC/grid_daily_precip/`\n#'\n#' @param file Full path to the netCDF precipitation file.\n#' @param tb_countries Tibble with the ISO-3 country code (`tb_countries`),\n#'   the name of the country (`country_name`), the short name of the country \n#'   (`country_name_short`) and a name suitable for a filename \n#'   (`country_name_clear`).\n#' @param country_names Name of the countries for which to extract daily obs.\n#' @param maps_level_0 List of level 0 borders from shapefiles provided by GDAM.\n#' @param value_type Type of values retrieved (`\"precip\"`, `\"tmin\"` or `\"max\"`).\n#' \nextract_daily_grid &lt;- function(file,\n                               tb_countries,\n                               country_names,\n                               maps_level_0, \n                               value_type = c(\"precip\", \"tmin\", \"tmax\")) {\n  # Extract the year of the observation from the file name\n  year &lt;- str_extract(file, str_c(value_type, \"\\\\.([[:digit:]]*)\\\\.nc\")) |&gt;\n    str_remove(str_c(value_type, \"\\\\.\")) |&gt;\n    str_remove(\"\\\\.nc\")\n  \n  # Raster Brick\n  weather_data_raw &lt;- brick(file)\n  weather_data &lt;- rotate(weather_data_raw)\n  \n  cli::cli_progress_bar(total = nrow(tb_countries))\n  # for (country_name in tb_countries$country_name) {\n  for (country_name in country_names) {\n    # Corresponding ISO code\n    country_code &lt;- tb_countries |&gt;\n      filter(country_name == !!country_name) |&gt;\n      pull(\"country_code\")\n    \n    current_country_map &lt;- maps_level_0[[country_code]]\n    \n    if (country_name %in% c(\"Fiji\", \"New Zealand\")) {\n      # re-center geographical coordinates for a Pacific view\n      current_country_map &lt;- st_shift_longitude(current_country_map)\n      weather_data_current &lt;- weather_data_raw\n    } else {\n      weather_data_current &lt;- weather_data\n    }\n    \n    current_country_map_large &lt;- st_buffer(current_country_map, dist = 70000)\n    \n    # Crop accordingly to the bounding box (+ some buffer)\n    e_country &lt;- sf::st_bbox(current_country_map)\n    # Enlarge a bit so that more cells are imported for each the country\n    e_country[[\"xmin\"]] &lt;- e_country[[\"xmin\"]] - .5\n    e_country[[\"xmax\"]] &lt;- e_country[[\"xmax\"]] + .5\n    e_country[[\"ymin\"]] &lt;- e_country[[\"ymin\"]] - .5\n    e_country[[\"ymax\"]] &lt;- e_country[[\"ymax\"]] + .5\n    \n    rb_country &lt;- crop(weather_data_current, e_country)\n    \n    # From the Rasterbox to a tibble\n    sf_country &lt;- stars::st_as_stars(rb_country) |&gt;\n      sf::st_as_sf()\n    \n    # Centroids of each cell of the grid\n    centroids &lt;- sf::st_centroid(sf_country)\n    centroids_grid &lt;- as_tibble(sf::st_coordinates(centroids)) |&gt;\n      dplyr::mutate(\n        grid_id = str_c(country_code, row_number(), sep = \"_\"),\n        country_code = country_code\n      ) |&gt;\n      dplyr::rename(longitude = X, latitude = Y)\n    \n    # Compute the intersection between the country and each cell of the grid\n    intersect_area &lt;- map_dbl(\n      .x = 1:nrow(sf_country),\n      .f = function(i_cell) {\n        inters &lt;- suppressWarnings(suppressMessages(st_intersection(\n          x = sf_country |&gt; slice(i_cell),\n          y = maps_level_0[[country_code]]\n        )))\n        area &lt;- st_area(inters)\n        if (length(area) == 0) area &lt;- 0\n        area\n      }\n    )\n    \n    # Compute the intersection between the augmented country's border\n    # and each cell of the grid\n    intersect_area_larger &lt;- map_dbl(\n      .x = 1:nrow(sf_country),\n      .f = function(i_cell) {\n        inters &lt;- suppressWarnings(suppressMessages(st_intersection(\n          x = sf_country |&gt; slice(i_cell),\n          y = current_country_map_large\n        )))\n        area &lt;- st_area(inters)\n        if (length(area) == 0) area &lt;- 0\n        area\n      }\n    )\n    \n    # Create the grid\n    weather_grid_country &lt;- cbind(sf_country, centroids_grid) |&gt;\n      mutate(\n        intersect_area = intersect_area,\n        intersect_area_larger = intersect_area_larger\n      ) |&gt;\n      tidyr::pivot_longer(\n        cols = -c(\n          geometry, longitude, latitude,\n          grid_id, country_code, intersect_area, intersect_area_larger\n        ),\n        names_to = \"date_v\"\n      ) |&gt;\n      dplyr::mutate(date = str_remove(date_v, \"^X\") |&gt; lubridate::ymd()) |&gt;\n      dplyr::select(-date_v) |&gt; \n      dplyr::filter(intersect_area_larger &gt; 0) |&gt; \n      dplyr::select(-intersect_area_larger)\n    \n    file_name &lt;- str_c(country_code, \"_\", year, \".RData\")\n    \n    save(\n      weather_grid_country,\n      file = str_c(\n        \"../Data/Weather/CPC/grid_daily_\", \n        value_type, \"/\", file_name\n      )\n    )\n    cli::cli_progress_update(inc = 1)\n  }\n  NULL\n}\nThe start and end years for the data to download:\nstart_year &lt;- 1980\nend_year &lt;- 2024\nWe saw in Chapter 2 that for New Zealand, the bounding box causes issues: the minimum longitude is close to -180° and the maximum is close to +180°. Hence, the bounding box will lead to import too many tiles.\nbboxes &lt;- list(\n  \n)\nbboxes$NZL[[\"xmin\"]] &lt;- 167\nbboxes$NZL[[\"xmax\"]] &lt;- 179\nbboxes$NZL[[\"ymin\"]] &lt;- -48\nbboxes$NZL[[\"ymax\"]] &lt;- -34",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Weather Data: Download</span>"
    ]
  },
  {
    "objectID": "data-weather-download.html#sec-extract-raw-data",
    "href": "data-weather-download.html#sec-extract-raw-data",
    "title": "3  Weather Data: Download",
    "section": "",
    "text": "First, we download the daily data from the NOAA PSL’s website, covering the period from 1980 to 2024. Each file containing the raw data correspond to a year and a metric (precipitation, min temperature, max temperature).\nSecond, using a function that we define, we extract the cells of the grid that correspond to each country. For each year, country, and metric we save the extracted raw data in a RData file.\nThird, we load all the extracted daily data into R and create a tibble for each country.\n\n\n\n\n\n\n\n\n3.1.1 Precipitation\nWe create the folder that will contain the raw data and the temporary (year x country) precipitation data.\n\nif (!dir.exists(\"../data/Weather/CPC/grid_daily_precip/\")) {\n  dir.create(\"../data/Weather/CPC/grid_daily_precip/\", recursive = TRUE)\n}\n\nThe URLs of the files we want to download:\n\nurls &lt;- str_c(\n  \"https://downloads.psl.noaa.gov/\",\n  \"Datasets/cpc_global_precip/precip.\", seq(start_year, end_year), \".nc\"\n)\n\nLet us loop on these URLs to download the worldwide daily data for each year:\n\nif (download_data == TRUE) {\n  for (file in urls) {\n    file_name &lt;- str_extract(file, \"cpc_global_precip/(.*)$\") |&gt;\n      str_remove(\"cpc_global_precip/\")\n    dest_file &lt;- str_c(\"../data/Weather/CPC/grid_daily_precip/\", file_name)\n    download.file(file, destfile = dest_file)\n  }\n}\n\nThen, we can load the raw data in R and apply the extract_daily_grid() function to extract the daily precipitation for each country.\n\nN &lt;- list.files(\n  \"../data/Weather/CPC/grid_daily_precip/\",\n  pattern = \"*\\\\.nc\", full.names = TRUE\n)\n\nExtracting values for the countries of interest:\n\nfor(i in 1:length(N)) {\n  cat(str_c(N[i], \"\\nNumber \", i , \"/\", length(N)))\n  extract_daily_grid(\n    file = N[i], \n    tb_countries = tb_countries, \n    country_names = c(\"New Zealand\"), \n    maps_level_0 = maps_level_0, \n    value_type = \"precip\"\n  )\n}\n\n\n\n3.1.2 Maximum Temperatures\nWe create the folder that will contain the raw data and the temporary (year x country) maximum temperature data.\n\nif (!dir.exists(\"../data/Weather/CPC/grid_daily_tmax/\")) {\n  dir.create(\"../data/Weather/CPC/grid_daily_tmax/\")\n}\n\nThe URLs of the files we want to download:\n\nurls &lt;- str_c(\n  \"https://downloads.psl.noaa.gov/\",\n  \"Datasets/cpc_global_temp/tmax.\", seq(start_year, end_year), \".nc\"\n)\n\nLet us loop on these URLs to download the worldwide daily data for each year:\n\nif (download_data == TRUE) {\n  for (file in urls) {\n    file_name &lt;- str_extract(file, \"cpc_global_temp/(.*)$\") |&gt;\n      str_remove(\"cpc_global_temp/\")\n    download.file(\n      file,\n      destfile = str_c(\"../data/Weather/CPC/grid_daily_tmax/\", file_name)\n    )\n  }\n}\n\nThen, we can load the raw data in R and apply the extract_daily_grid() function to extract the daily maximum temperatures for each country.\n\nN &lt;- list.files(\n  \"../data/Weather/CPC/grid_daily_tmax/\",\n  pattern = \"*\\\\.nc\", full.names = TRUE\n)\n\nExtracting values for the countries of interest:\n\nfor(i in 1:length(N)) {\n  cat(N[i])\n  cat(str_c(N[i], \"\\nNumber \", i , \"/\", length(N)))\n  extract_daily_grid(\n    file = N[i], \n    tb_countries = tb_countries, \n    country_names = c(\"New Zealand\"), \n    maps_level_0 = maps_level_0, \n    value_type = \"tmax\"\n  )\n}\n\n\n\n3.1.3 Minimum Temperatures\nWe create the folder that will contain the raw data and the temporary (year x country) minimum temperature data.\n\nif (!dir.exists(\"../data/Weather/CPC/grid_daily_tmin/\")) {\n  dir.create(\"../data/Weather/CPC/grid_daily_tmin/\")\n}\n\nThe URLs of the files we want to download:\n\nurls &lt;- str_c(\n  \"https://downloads.psl.noaa.gov/\",\n  \"Datasets/cpc_global_temp/tmin.\", seq(start_year, end_year), \".nc\"\n)\n\nLet us loop on these URLs to download the worldwide daily data for each year:\n\nif (download_data == TRUE) {\n  for (file in urls) {\n    file_name &lt;- str_extract(file, \"cpc_global_temp/(.*)$\") |&gt;\n      str_remove(\"cpc_global_temp/\")\n    download.file(\n      file,\n      destfile = str_c(\"../data/Weather/CPC/grid_daily_tmin/\", file_name)\n    )\n  }\n}\n\nThen, we can load the raw data in R and apply the extract_daily_grid() function to extract the daily minimum temperatures for each country.\n\nN &lt;- list.files(\n  \"../data/Weather/CPC/grid_daily_tmin/\",\n  pattern = \"*\\\\.nc\", full.names = TRUE\n)\n\nExtracting values for the countries of interest:\n\nfor(i in 1:length(N)) {\n  cat(N[i])\n  cat(str_c(N[i], \"\\nNumber \", i , \"/\", length(N)))\n  extract_daily_grid(\n    file = N[i], \n    tb_countries = tb_countries, \n    country_names = c(\"New Zealand\"), \n    maps_level_0 = maps_level_0, \n    value_type = \"tmin\"\n  )\n}",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Weather Data: Download</span>"
    ]
  },
  {
    "objectID": "data-weather-missing.html",
    "href": "data-weather-missing.html",
    "title": "4  Weather Data: Missing Data",
    "section": "",
    "text": "4.1 Import Data\nLet us load the graphs theme functions (See Chapter 1):\nLet us also load the maps for the countries of interest (See Chapter 2).\nWe focus on the countries defined in Chapter 2:\nWe define a function, load_daily(), which loads the daily data obtained in Chapter 3.\n#' Loads a weather data from country x year\n#'\n#' @param file path to the file to load\nload_daily &lt;- function(file) {\n  load(file)\n  weather_grid_country\n}\nLet us focus on New Zealand.\ncountry &lt;- \"New Zealand\"\nWe extract the corresponding country code:\ncountry_code &lt;- tb_countries |&gt;\n  dplyr::filter(country_name == !!country) |&gt;\n  dplyr::pull(\"country_code\")\nWe list the files that contain the daily data for the current country:\nN &lt;- list(\n  precip = \"../Data/Weather/CPC/grid_daily_precip/\",\n  tmin = \"../Data/Weather/CPC/grid_daily_tmin/\",\n  tmax = \"../Data/Weather/CPC/grid_daily_tmax/\"\n) |&gt;\n  map(~list.files(.x, full.names = TRUE, pattern = str_c(country_code, \"_\")))\nLet us load these files:\n# Load precip, tmin and tmax\ncountry_precip_daily &lt;- map(N$precip, load_daily) |&gt;list_rbind()\ncountry_tmin_daily &lt;- map(N$tmin, load_daily) |&gt;list_rbind()\ncountry_tmax_daily &lt;- map(N$tmax, load_daily) |&gt;list_rbind()\nLet us merge these datasets:\ncountry_weather_daily &lt;- country_precip_daily |&gt;\n    dplyr::mutate(variable = \"precip\") |&gt;\n    bind_rows(\n      country_tmin_daily  |&gt; mutate(variable = \"tmin\")\n    ) |&gt;\n    bind_rows(\n      country_tmax_daily  |&gt; mutate(variable = \"tmax\")\n    ) |&gt;\n    dplyr::select(-grid_id) |&gt;\n  pivot_wider(values_from = value, names_from = variable) |&gt; \n  group_by(longitude, latitude) |&gt; \n  dplyr::mutate(cell_id = cur_group_id()) |&gt; \n  ungroup()\nWe extract information about longitude / latitude and geometry of each cell:\ncells &lt;- country_weather_daily |&gt; \n  dplyr::select(cell_id, longitude, latitude, geometry, intersect_area) |&gt; \n  unique()\n\ncells &lt;- cells |&gt; dplyr::mutate(country = !!country)\nLet us transform this object as an sf object:\ncells_sf &lt;- st_as_sf(cells)\nWe can have a look at the number of values per cell.\n# This code is not evaluated here.\n#| code-fold: true\nggplot() + \n  geom_sf(\n    data = st_as_sf(cells) |&gt; \n      left_join(\n        country_weather_daily |&gt; group_by(cell_id) |&gt; count() |&gt; \n          arrange(n),\n        by = \"cell_id\"\n      ),\n    mapping = aes(fill = n)\n  ) +\n  geom_sf(\n    data = maps_level_0_NZ$NGA,\n    fill = NA, col = \"black\"\n  )\nWe can identify the cells for which the number of records is lower than the max number of records:\ncells_to_remove &lt;- \n  country_weather_daily |&gt; group_by(cell_id) |&gt; count() |&gt; \n  ungroup() |&gt; \n  mutate(max = max(n)) |&gt; \n  filter(n &lt; max)\n# This code is not evaluated here.\n#| code-fold: true\nggplot() + \n  geom_sf(\n    data = st_as_sf(cells) |&gt; \n      left_join(\n        country_weather_daily |&gt; group_by(cell_id) |&gt; count() |&gt; \n          arrange(n),\n        by = \"cell_id\"\n      ) |&gt; \n      left_join(\n        cells_to_remove |&gt; select(cell_id) |&gt; \n          mutate(to_remove = TRUE)\n      ) |&gt; \n      mutate(to_remove = replace_na(to_remove, FALSE)),\n    mapping = aes(fill = to_remove)\n  ) +\n  geom_sf(\n    data = maps_level_0_NZ,\n    fill = NA, col = \"black\"\n  ) +\n  scale_fill_manual(\n    \"Remove\", \n    values = c(`TRUE` = \"red\", `FALSE` = NA)\n  )\nLet us remove those cells:\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  filter(! cell_id %in% cells_to_remove$cell_id)\nWe also remove the cells corresponding to islands for which we will have no agricultural records.\nids_islands &lt;- c(\n  1, 2, 5, 6, 24, 25, 34, 35, 45, 46, 55, 56, 256, 250, 249, 255,\n  264, 267, 263, 266, 261, 260, 259, 262, 265\n)\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  filter(\n    ! cell_id %in% ids_islands\n  )\nCode\n# This chunk is not evaluated here.\nggplot() + \n  geom_sf(\n    data = st_as_sf(cells) |&gt; \n      inner_join(\n        country_weather_daily |&gt; group_by(cell_id) |&gt; count() |&gt; \n          arrange(n),\n        by = \"cell_id\"\n      ),\n    fill = \"red\"\n  ) +\n  geom_sf(\n    data = maps_level_0_NZ,\n    fill = NA, col = \"black\"\n  )\ncells &lt;- \n  cells |&gt; filter(\n  ! cell_id %in% c(cells_to_remove$cell_id, ids_islands)\n)\n\ncells_sf &lt;- st_as_sf(cells)\nLet us save this grid:\nsave(\n  cells,\n  file = str_c(\"../data/Weather/CPC/\", country_code, \"_cells.RData\")\n)\nWe remove the geometry from the table:\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  dplyr::select(-geometry, -intersect_area)\nThe total number of observations:\nscales::number(nrow(country_weather_daily), big.mark = \",\")\n\n[1] \"2,975,097\"",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Weather Data: Missing Data</span>"
    ]
  },
  {
    "objectID": "data-weather-missing.html#missing-values",
    "href": "data-weather-missing.html#missing-values",
    "title": "4  Weather Data: Missing Data",
    "section": "4.2 Missing Values",
    "text": "4.2 Missing Values\nHow many missing values are there here in the dataset?\n\ncountry_weather_daily |&gt; \n  summarise(across(everything(), ~sum(is.na(.x))))\n\n# A tibble: 1 × 8\n  longitude latitude country_code  date precip   tmin   tmax cell_id\n      &lt;int&gt;    &lt;int&gt;        &lt;int&gt; &lt;int&gt;  &lt;int&gt;  &lt;int&gt;  &lt;int&gt;   &lt;int&gt;\n1         0        0            0     0  16895 446893 445241       0\n\n\n\n4.2.1 Precipitation\nThe number of missing data for precipitation per cell:\n\ntb_nb_na_precip &lt;- country_weather_daily |&gt; \n  group_by(cell_id) |&gt; \n  select(cell_id, precip) |&gt; \n  summarise(nb_na_precip = sum(is.na(precip))) |&gt; \n  arrange(desc(nb_na_precip))\ntb_nb_na_precip\n\n# A tibble: 181 × 2\n   cell_id nb_na_precip\n     &lt;int&gt;        &lt;int&gt;\n 1     153         9875\n 2       9           39\n 3      12           39\n 4      13           39\n 5      14           39\n 6      19           39\n 7      20           39\n 8      21           39\n 9      22           39\n10      27           39\n# ℹ 171 more rows\n\n\nWhat if we look at missing values per cell and day?\n\ncountry_weather_daily |&gt; \n  group_by(date) |&gt; \n  summarise(nb_na_precip = sum(is.na(precip))) |&gt; \n  filter(nb_na_precip &gt; 0) |&gt; \n  arrange(desc(nb_na_precip)) |&gt; \n  DT::datatable()\n\n\n\n\n\nAnd by cell?\n\nggplot() +\n  geom_sf(\n    data = cells_sf |&gt; \n      left_join(tb_nb_na_precip),\n    alpha = .2,\n    mapping = aes(fill = nb_na_precip)\n  ) +\n  geom_sf(data = maps_level_0_NZ, fill = NA) +\n  scale_fill_gradient(\"NAs Min Temperature\", low = \"white\", high = \"red\") +\n  theme_map_paper()\n\nJoining with `by = join_by(cell_id)`\n\n\n\n\n\nFigure 4.1: Number of missing values for precipitation per cell\n\n\n\n\n\n\n\n\nMost missing precipitation observations are from cell 153 which is covering a tiny fraction of land.\n\n\n4.2.2 Minimum Temperatures\nNow, let us do the same for min temperatures:\n\ntb_nb_na_tmin &lt;- country_weather_daily |&gt; \n  group_by(cell_id) |&gt; \n  select(cell_id, tmin) |&gt; \n  summarise(nb_na_tmin = sum(is.na(tmin))) |&gt; \n  arrange(desc(nb_na_tmin))\ntb_nb_na_tmin\n\n# A tibble: 181 × 2\n   cell_id nb_na_tmin\n     &lt;int&gt;      &lt;int&gt;\n 1     152      16437\n 2     171      16437\n 3     196      16437\n 4     221      16437\n 5     239      16437\n 6     258      16437\n 7       9       6979\n 8      14       6979\n 9      22       6979\n10      27       6979\n# ℹ 171 more rows\n\n\n\nggplot() +\n  geom_sf(\n    data = cells_sf |&gt; \n      left_join(tb_nb_na_tmin),\n    alpha = .2,\n    mapping = aes(fill = nb_na_tmin)\n  ) +\n  geom_sf(data = maps_level_0_NZ, fill = NA) +\n  scale_fill_gradient(\"Min Temperature\", low = \"white\", high = \"red\") +\n  theme_map_paper()\n\nJoining with `by = join_by(cell_id)`\n\n\n\n\n\nFigure 4.2: Number of missing values for minimum temperatures per cell\n\n\n\n\n\n\n\n\nSpatially, missing observation are mostly on coastal areas.\nFor each cell, the number of daily observations from 1980-01-01 to 2024-12-31 is:\n\nseq(\n  min(country_weather_daily$date), \n  max(country_weather_daily$date), \n  by = \"day\"\n) |&gt; \n  length()\n\n[1] 16437\n\n\nWhat if we look at missing values per cell and day?\n\ncountry_weather_daily |&gt; \n  group_by(date) |&gt; \n  summarise(nb_na_tmin = sum(is.na(tmin))) |&gt; \n  filter(nb_na_tmin &gt; 10) |&gt; \n  arrange(desc(nb_na_tmin)) |&gt; \n  DT::datatable()\n\n\n\n\n\n\n\n4.2.3 Maximum Temperatures\nAnd for max temperatures:\n\ntb_nb_na_tmax &lt;- \n  country_weather_daily |&gt; \n  group_by(cell_id) |&gt; \n  select(cell_id, tmax) |&gt; \n  summarise(nb_na_tmax = sum(is.na(tmax))) |&gt; \n  arrange(desc(nb_na_tmax))\ntb_nb_na_tmax\n\n# A tibble: 181 × 2\n   cell_id nb_na_tmax\n     &lt;int&gt;      &lt;int&gt;\n 1     152      16437\n 2     171      16437\n 3     196      16437\n 4     221      16437\n 5     239      16437\n 6     258      16437\n 7       9       6971\n 8      14       6971\n 9      22       6971\n10      27       6971\n# ℹ 171 more rows\n\n\n\nggplot() +\n  geom_sf(\n    data = cells_sf |&gt; \n      left_join(tb_nb_na_tmax),\n    alpha = .2,\n    mapping = aes(fill = nb_na_tmax)\n  ) +\n  geom_sf(data = maps_level_0_NZ, fill = NA) +\n  scale_fill_gradient(\"Max Temperature\", low = \"white\", high = \"red\") +\n  theme_map_paper()\n\nJoining with `by = join_by(cell_id)`\n\n\n\n\n\nFigure 4.3: Number of missing values for maximum temperatures per cell\n\n\n\n\n\n\n\n\nWhat if we look at missing values per cell and day?\n\ncountry_weather_daily |&gt; \n  group_by(date) |&gt; \n  summarise(nb_na_tmax = sum(is.na(tmax))) |&gt; \n  filter(nb_na_tmax &gt; 10) |&gt; \n  arrange(desc(nb_na_tmax)) |&gt; \n  DT::datatable()",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Weather Data: Missing Data</span>"
    ]
  },
  {
    "objectID": "data-weather-missing.html#temporal-interpolation",
    "href": "data-weather-missing.html#temporal-interpolation",
    "title": "4  Weather Data: Missing Data",
    "section": "4.3 Temporal Interpolation",
    "text": "4.3 Temporal Interpolation\nLet us use splines at the cell level to interpolate missing values for which no more than 5 consecutive values are missing. We will then address the interpolation of missing values for the south-western cells.\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  arrange(date) |&gt; \n  nest(.by = cell_id) |&gt; \n  mutate(\n    precip_new = map(data, ~{\n      if (sum(is.na(.x$precip)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$precip, maxgap = 5, option = \"spline\")\n      }\n      new_val}\n    ),\n    tmin_new = map(data, ~{\n      if (sum(is.na(.x$tmin)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$tmin, maxgap = 5, option = \"spline\")\n      }\n      new_val}\n    ),\n    tmax_new = map(data, ~{\n      if (sum(is.na(.x$tmax)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$tmax, maxgap = 5, option = \"spline\")\n      }\n      new_val}\n    )\n  ) |&gt; \n  unnest(cols = c(data, precip_new, tmin_new, tmax_new))\n\nRegistered S3 method overwritten by 'quantmod':\n  method            from\n  as.zoo.data.frame zoo \n\n\nWith the interpolation, there might be negative values, which is not possible for precipitation. We set to 0 precipitation for which interpolated values are negative.\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  mutate(\n    precip_new = ifelse(precip_new &lt; 0, 0, precip_new)\n  )",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Weather Data: Missing Data</span>"
    ]
  },
  {
    "objectID": "data-weather-missing.html#spatial-interpolation",
    "href": "data-weather-missing.html#spatial-interpolation",
    "title": "4  Weather Data: Missing Data",
    "section": "4.4 Spatial Interpolation",
    "text": "4.4 Spatial Interpolation\nNow, let us address the problem of the remaining cells for which we have some missing observation. First, we identify cells IDs for which observations are missing for precipitation, and for min and max temperatures.\n\ncell_id_missing_precip &lt;- \n  tb_nb_na_precip |&gt; pull(cell_id)\ncell_id_missing_tmin &lt;- \n  tb_nb_na_tmin |&gt; pull(cell_id)\ncell_id_missing_tmax &lt;- \n  tb_nb_na_tmax |&gt; pull(cell_id)\n\nWe will replace the missing observations with weighted averages of the values found in the neighbors cells. We will consider the 5 nearest cells and use the inverse distance to those as the weights in the weighted average.\nFirst, let us get the distance matrix of the cells, using the centroid of each cell as the reference point.\n\ncentroids_cells &lt;- sf::st_centroid(cells_sf)\n\nWarning: st_centroid assumes attributes are constant over geometries\n\ndistance_matrix &lt;- sf::st_distance(centroids_cells, centroids_cells)\n\nWe can then define the find_neighbors_radius() function which returns the cells within a radius of another cell:\n\n#' Identifies the neighbors of a cell given a radius\n#' @param id cell id\n#' @param radius radius in metres to identify the neighbors\nfind_neighbors_radius &lt;- function(id, radius) {\n  ind_current_cell &lt;- which(cells_sf$cell_id == id)\n  tibble(\n    cell_id = id,\n    cell_id_neighbors = cells_sf$cell_id,\n    distance = units::drop_units(distance_matrix[, ind_current_cell])\n  ) |&gt; \n    arrange(distance) |&gt; \n    filter(cell_id_neighbors != !!id) |&gt; \n    filter(distance &lt;= !!radius)\n}\n\nFor example, for cell ID 12, the cells within 150km radius:\n\nexample_nn &lt;- find_neighbors_radius(id = 12, 150*1000)\nexample_nn\n\n# A tibble: 14 × 3\n   cell_id cell_id_neighbors distance\n     &lt;dbl&gt;             &lt;int&gt;    &lt;dbl&gt;\n 1      12                19   38446.\n 2      12                13   55597.\n 3      12                 9   67695.\n 4      12                20   67695.\n 5      12                29   76893.\n 6      12                28   94601.\n 7      12                30   95169.\n 8      12                14  111194.\n 9      12                39  115338.\n10      12                21  117767.\n11      12                38  127563.\n12      12                40  128510.\n13      12                27  134789.\n14      12                31  135586.\n\n\n\n\nCode\ncreate_circle &lt;- function(long, lat, radius){ \n  tibble(degree = 1:360) |&gt; \n    rowwise() |&gt; \n    mutate(\n      long = geosphere::destPoint(c(long, lat), degree, radius)[1],\n      lat = geosphere::destPoint(c(long, lat), degree, radius)[2]\n    ) |&gt; \n    ungroup()\n}\n\ncell_of_interest &lt;- centroids_cells |&gt; filter(cell_id == 12)\ncircle_sf &lt;- create_circle(\n  long = cell_of_interest$longitude,\n  lat = cell_of_interest$latitude,\n  radius = 150*1000\n) |&gt; \n  st_as_sf(coords = c(\"long\", \"lat\"), crs = sf::st_crs(centroids_cells)) |&gt; \n  summarise(geometry = st_combine(geometry)) %&gt;% \n  st_cast(\"POLYGON\")\n\nggplot() +\n  geom_sf(\n    data = cells_sf |&gt; \n      mutate(\n        type = case_when(\n          cell_id == 12 ~ \"Cell 12\",\n          cell_id %in% example_nn$cell_id_neighbors ~ \"Neighbors\",\n          TRUE ~ \"Other\"\n        )\n      ),\n    mapping = aes(fill = type),\n    colour = \"black\"\n  ) + \n  geom_sf(data = maps_level_0$NGA, fill = NA) +\n  geom_sf(\n    data = circle_sf, \n    color = \"black\", fill = NA, linewidth = .8, linetype = \"dashed\"\n  ) +\n  scale_fill_manual(\n    NULL, \n    values = c(\"Cell 12\" = \"#D55E00\", \"Neighbors\" = \"#009E73\", \"Other\" = \"lightgray\")\n  ) +\n  theme_map_paper() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nFigure 4.4: Cells within a 150km radius from cell 12\n\n\n\n\n\n\n\n\nNow, let us get all the neighbors of the cells with many missing values for min temperatures, and for max temperatures.\n\nneighbors_precip &lt;- \n  map(cell_id_missing_precip, ~find_neighbors_radius(id = .x, radius = 150*1000)) |&gt; \n  list_rbind()\n\nneighbors_tmin &lt;- \n  map(cell_id_missing_tmin, ~find_neighbors_radius(id = .x, radius = 150*1000)) |&gt; \n  list_rbind()\n\nneighbors_tmax &lt;- \n  map(cell_id_missing_tmax, ~find_neighbors_radius(id = .x, radius = 150*1000)) |&gt; \n  list_rbind()\n\nWe then define the impute_na_neighbor_cells() function that identifies the values of a metric of interest (argument name_col) from the neighbor (found in argument neighbors) cells of a given cell (whose ID is given to the argument id).\n\n#' @param id cell ID\n#' @param neighbors tibble with distances of the neighbors (obtained with \n#'  `find_neighbors_radius()`)\n#' @param name_col name of the columns in `country_weather_daily` to use to \n#'  impute data (from neighbors)\nimpute_na_neighbor_cells &lt;- function(id, neighbors, name_col) {\n  country_weather_daily |&gt; filter(cell_id == !!id) |&gt; \n    left_join(neighbors, relationship = \"many-to-many\", by = \"cell_id\") |&gt; \n    left_join(\n      country_weather_daily |&gt;\n        select(\n          cell_id_neighbors = cell_id, \n          date,\n          new_val_neighbors = !!sym(name_col)\n        ) |&gt; \n        sf::st_drop_geometry(),\n      by = c(\"date\", \"cell_id_neighbors\")\n    ) |&gt; \n    select(date, cell_id, cell_id_neighbors, new_val_neighbors, distance) |&gt; \n    filter(!is.na(new_val_neighbors)) |&gt; \n    group_by(cell_id, date) |&gt; \n    mutate(weight_distance = distance / sum(distance)) |&gt; \n    mutate(new_val_neighbors = new_val_neighbors * weight_distance) |&gt; \n    summarise(\n      new_val_neighbors = sum(new_val_neighbors),\n      .groups = \"drop\"\n    )\n}\n\nWe apply this function to the cells for which many missing values were found, to impute values for min temperatures, and then for max temperatures.\n\nneighbors_precip_new_val &lt;- \n  map(\n    cell_id_missing_precip, \n    ~impute_na_neighbor_cells(\n      .x, neighbors = neighbors_precip, name_col = \"precip_new\")\n  ) |&gt; \n  list_rbind()\n\nneighbors_tmin_new_val &lt;- \n  map(\n    cell_id_missing_tmin, \n    ~impute_na_neighbor_cells(\n      .x, neighbors = neighbors_tmin, name_col = \"tmin_new\")\n  ) |&gt; \n  list_rbind()\n\nneighbors_tmax_new_val &lt;- \n  map(\n    cell_id_missing_tmax, \n    ~impute_na_neighbor_cells(\n      .x, neighbors = neighbors_tmax, name_col = \"tmax_new\")\n  ) |&gt; \n  list_rbind()\n\nWe replace the missing values in the table with daily observations:\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  left_join(\n    neighbors_precip_new_val |&gt; rename(precip_neighbors = new_val_neighbors)\n  ) |&gt; \n  left_join(\n    neighbors_tmin_new_val |&gt; rename(tmin_neighbors = new_val_neighbors)\n  ) |&gt; \n  left_join(\n    neighbors_tmax_new_val |&gt; rename(tmax_neighbors = new_val_neighbors)\n  ) |&gt; \n  mutate(\n    # If temporal interpolation was not enough, replace with spatially\n    # interpolated values\n    precip_new = ifelse(is.na(precip_new), precip_neighbors, precip_new),\n    tmin_new = ifelse(is.na(tmin_new), tmin_neighbors, tmin_new),\n    tmax_new = ifelse(is.na(tmax_new), tmax_neighbors, tmax_new)\n  )",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Weather Data: Missing Data</span>"
    ]
  },
  {
    "objectID": "data-weather-missing.html#second-temporal-interpolation",
    "href": "data-weather-missing.html#second-temporal-interpolation",
    "title": "4  Weather Data: Missing Data",
    "section": "4.5 Second Temporal Interpolation",
    "text": "4.5 Second Temporal Interpolation\nThere are still missing values:\n\nprecip: 2015-05-19 to 2015-05-26,\ntmin and tmax: 1983-04-25 to 1983-04-30 and 2015-05-21 to 2015-05-26.\n\n\ncountry_weather_daily |&gt; filter(is.na(precip_new)) |&gt; count(date)\ncountry_weather_daily |&gt; filter(is.na(tmin_new)) |&gt; count(date)\ncountry_weather_daily |&gt; filter(is.na(tmax_new)) |&gt; count(date)\n\nFor those observations, we use, again, a temporal interpolation. This time, we increase the windows’ width to 10 days.\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  arrange(date) |&gt; \n  nest(.by = cell_id) |&gt; \n  mutate(\n    precip_new_2 = map(data, ~{\n      if (sum(is.na(.x$precip_new)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$precip_new, maxgap = 10, option = \"spline\")\n      }\n      new_val}\n    ),\n    tmin_new_2 = map(data, ~{\n      if (sum(is.na(.x$tmin_new)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$tmin_new, maxgap = 10, option = \"spline\")\n      }\n      new_val}\n    ),\n    tmax_new_2 = map(data, ~{\n      if (sum(is.na(.x$tmax_new)) &gt;= nrow(.x)-1) {\n        new_val &lt;- NA\n      } else {\n        new_val &lt;- imputeTS::na_interpolation(.x$tmax_new, maxgap = 10, option = \"spline\")\n      }\n      new_val}\n    )\n  ) |&gt; \n  unnest(cols = c(data, precip_new_2, tmin_new_2, tmax_new_2)) |&gt; \n  mutate(\n    precip_new_2 = ifelse(precip_new_2 &lt; 0, 0, precip_new_2),\n    precip_new = ifelse(is.na(precip_new), precip_new_2, precip_new),\n    tmin_new = ifelse(is.na(tmin_new), tmin_new_2, tmin_new),\n    tmax_new = ifelse(is.na(tmax_new), tmax_new_2, tmax_new)\n  )\n\nLastly, we remove the raw values with missing data with the columns in which missing data were replaced.\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  dplyr::select(\n    -precip, -tmin, -tmax, \n    -precip_neighbors, -tmin_neighbors, -tmax_neighbors,\n    -precip_new_2, -tmin_new_2, -tmax_new_2\n  ) |&gt; \n  rename(precip = precip_new, tmin = tmin_new, tmax = tmax_new)\n\nLet us save the results for later use.\n\nsave(\n  country_weather_daily,\n  file = \"../data/Weather/CPC/NZL_daily_weather_corrected.rda\"\n)\n\nEach row gives three metrics for a grid cell identified with its ID (cell_id) whose centroid’s coordinates are given in longitude and latitude, at a given day (date). The country the data refer to (Nigeria) is stated in column country_code. The metrics are total rainfall (precip), minimum temperature (tmin) and maximum temperature (tmax).\nThe content of this dataset is summarized in Table 4.1.\n\n\n\nTable 4.1: Data dictionary for NGA_daily_weather_corrected.rda\n\n\n\n\n\nVariable name\nType\nDescription\n\n\n\n\nlongitude\nnumeric\nLongitude of the centroid of the cell\n\n\nlatitude\nnumeric\nLatitude of the centroid of the cell\n\n\ncountry_code\nnumeric\nCountry code (ISO 3166-1 alpha-3 code)\n\n\ndate\ndate\nDate of the observation (YYYY-MM-DD)\n\n\ncell_id\ninteger\nUnique identifier of the cells of the grid\n\n\nprecip\nnumeric\nTotal rainfall, in mm\n\n\ntmin\nnumeric\nMinimum temperature, in °C\n\n\ntmax\nnumeric\nMaximum temperature, in °C",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Weather Data: Missing Data</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html",
    "href": "data-weather-metrics.html",
    "title": "5  Weather Data: Metrics",
    "section": "",
    "text": "5.1 Potential Evapotranspiration\nLet us load the graphs theme functions (See Chapter 1):\nLet us also load the maps for the countries of interest (See Chapter 2)\nWe focus on the following countries defined in Chapter 2:\nLastly, we load the weather data (see Chapter 4):\nWe rename the max and min temperature columns:\nLet us add the year, month, month name and day of year to the rows of the dataset:\nWe have daily precipitation \\(P_t\\), minimum temperatures \\(\\text{Tmin}_{t}\\) and maximum temperatures \\(\\text{Tmax}_{t}\\) at the grid cell level. We are interested in building a soil moisture index which requires to compute the evapotranspiration in a prior step. We follow the approach presented in Dingman (2015) (pp. 299–300, Box 6.8: Thornthwaite-Type Monthly Water-Balance Model) and recalled in Appendix S1 of Lutz, Wagtendonk, and Franklin (2010).",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html#sec-pet",
    "href": "data-weather-metrics.html#sec-pet",
    "title": "5  Weather Data: Metrics",
    "section": "",
    "text": "5.1.1 Potential Evapotranspiration\nThe daily PET (in mm/day) writes (assumed to be from Hamon (1964), but the article cannot be found on the Internet ; Dingman (2015) Eq. 6.68 p. 294): \\[\n\\text{PET}_t =\n\\begin{cases}\n0, & \\text{if }\\mathrm{Tmean}_t \\le 0^\\circ\\mathrm{C},\\\\\n29.8 \\times \\text{DL}_t \\times \\dfrac{e^\\star(\\mathrm{Tmean}_t)}{\\mathrm{Tmean}_t + 273.2}, & \\mathrm{otherwise},\n\\end{cases}\n\\tag{5.1}\\]\nwhere \\(\\text{DL}_t\\) is the day length of day \\(t\\), expressed in hours and \\(e^\\star(\\cdot)\\) gives the saturation vapour pressure.\n\\(\\text{Tmean}_t\\) is the daily average temperature: \\[\n\\mathrm{Tmean}_t = \\frac{\\mathrm{Tmin}_t + \\mathrm{Tmax}_t}{2}.\n\\tag{5.2}\\]\n\n\n\n\n\n\nHow to compute day length \\(\\text{DL}_t\\)?\n\n\n\n\n\nThe methodology to compute day length is given in Appendix D of Dingman (2015). It writes:\n\\[\n\\text{DL}_t = \\frac{24}{\\pi}\\omega_s,\n\\tag{5.3}\\]\nwhere \\(\\omega_s\\) (in radians) is the sunrise hour angle. At sunrise and sunset, the solar zenith angle \\(\\theta_z\\) equals \\(90^\\circ + h_0\\), where \\(h_0\\) is the apparent altitude of the Sun’s center at sunrise. The sunrise hour angle \\(\\omega_s\\) satisfies: \\[\n\\cos(\\omega_s) = \\dfrac{\\sin(h_0) - \\sin(\\Lambda) \\sin(\\delta)}{\\cos(\\Lambda) \\cos(\\delta)},\n\\tag{5.4}\\] with \\(\\Lambda\\) the latitude (in radians), \\(\\delta\\) the solar declination (in radians) and \\(h_0 \\approx -0.833^\\circ\\).\nThe solar declination in radians writes (Campbell and Norman (1998)): \\[\n\\sin^{-1}(0.39795 \\times \\cos(0.2163108 + 2 \\tan^{-1}(0.9671396 \\times \\tan(0.0086 \\times (\\text{doy}_t - 186))) ))\n\\tag{5.5}\\]\n\n\n\n\n\n\n\n\n\nHow to compute saturation vapour pressure \\(e^\\star(T)\\)?\n\n\n\n\n\nThe saturation vapour pressure \\(e^\\star(\\cdot)\\) (in k pascals) is given, for a temperature \\(T\\) (in °C), by (Dingman (2015), Box 2.2 p.99): \\[\ne^\\star(T) = 0.611 \\exp\\left(\\frac{17.27\\times T}{T + 237.3}\\right)\n\\tag{5.6}\\]\n\n\n\nLet us compute the daily potential evapotranspiration in R. We define two functions:\n\ndecl_angle(), which computes the solar declination in radians for a given day-of-year (the code is from {TrenchR}),\ndaylength_hours(), which computes the day length (in hours) for a given day-of-year, at a given latitude.\n\n\n\nThe decl_angle() function.\n#' @title Solar Declination in Radians (from {TrenchR})\n#' \n#' @description The function calculates solar declination, which is the angular \n#'  distance of the sun north or south of the earth's equator, based on the day \n#'   of year (Campbell and Norman, 1998)\n#' \n#' @param doy Day of year (1-366).\n#' \n#' @returns The declination angle (in radians).\n#'\n#' @references\n#' Campbell GS, Norman JM (1998). Introduction to environmental biophysics, \n#'  2nd ed. edition. Springer, New York. ISBN 0387949372.\ndecl_angle &lt;- function (doy) {\n  \n  doy &lt;- (doy - 1) %% 365 + 1\n  \n  rev_ang &lt;- 0.2163108 + 2 * atan(0.9671396 * tan(0.0086 * (doy -186))) \n  asin(0.39795 * cos(rev_ang)) \n  \n}\n\n\n\n\nThe daylength_hours() function.\n#' Day length (in hours)\n#' \n#' @param lat_deg Latitude (in degrees)\n#' @param doy Day of year (1-366).\n#' \ndaylength_hours &lt;- function(lat_deg, doy) {\n  \n  lambda &lt;- lat_deg * pi / 180\n  delta &lt;- decl_angle(doy)\n  h0 &lt;- -0.833 * pi / 180 # apparent sunrise altitude\n  \n  # General sunrise equation with altitude:\n  # cos(ws) = (sin(h0) - sin(lambda) sin(delta)) / (cos(lambda) cos(delta))\n  num &lt;- sin(h0) - sin(lambda) * sin(delta)\n  den &lt;- cos(lambda) * cos(delta)\n  cos_ws &lt;- num / den\n  cos_ws &lt;- pmin(pmax(cos_ws, -1), 1) # clamp to [-1,1]\n  ws &lt;- acos(cos_ws)\n  \n  (24/pi) * ws\n}\n\n\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  mutate(\n    temp_mean = (temp_min + temp_max) / 2,\n    dl_hours  = daylength_hours(latitude, day_of_year)\n  ) |&gt; \n  arrange(cell_id, date) |&gt; \n  # Daily PET (Hamon)\n  mutate(\n    esat = 0.611 * exp(17.27 * temp_mean / (temp_mean + 237.3)), # kPa\n    PET_daily = 29.8 * dl_hours * (esat / (temp_mean + 273.2)), # mm/day\n    PET_daily = if_else(temp_mean &lt;= 0, 0, PET_daily) # Hamon convention\n  )",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html#water-deficit-water-balance",
    "href": "data-weather-metrics.html#water-deficit-water-balance",
    "title": "5  Weather Data: Metrics",
    "section": "5.2 Water Deficit (Water Balance)",
    "text": "5.2 Water Deficit (Water Balance)\nThe equation for soil water balance depends on whether water input (\\(W_t\\)) exceeds potential evapostranspiration (Lutz, Wagtendonk, and Franklin (2010)):\n\\[\n\\text{SW}_t = \\begin{cases}\n\\min \\left\\{S_\\text{max}, (W_t - \\text{PET}_t) + \\text{SW}_{t-1}\\right\\},& \\text{if } W_t \\geq \\text{PET}_{t},\\\\\n\\text{SW}_{t-1} - \\Delta_{\\text{soil},t}, & \\text{otherwise},\n\\end{cases}\n\\tag{5.7}\\]\nwhere \\(\\Delta_{\\text{soil},t}\\) is the fraction removed from storage: \\[\n\\Delta_{\\text{soil},t} = \\text{SW}_{t-1} \\times\\left( 1 - \\exp\\left(-\\dfrac{\\text{PET}_t - W_t}{S_\\text{max}}\\right)\\right),\n\\tag{5.8}\\]\n\\(S_{\\text{max}}\\) is the soil water-holding capacity in the top 200 cm of the soil profile. Ideally, this should be given from recorded values. We do not have this here, so we will use a value of 150mm:\n\nThe current NIWA water balance model uses a fixed soil moisture capacity of 150 mm of water, based on a typical loam soil. https://niwa.co.nz/sites/default/files/NZDI_more_info.pdf (New Zealand Drought Index and Drought Monitor Framework).\n\nThe actual evapotranspiration, \\(\\text{AET}_t\\) writes: \\[\n\\text{AET}_t = \\begin{cases}\n\\text{PET}_t, & \\text{if } W_t \\geq \\text{PET}_{t},\\\\\nW_t + \\Delta_{\\text{soil},t}, & \\text{otherwise}.\n\\end{cases}\n\\]\nThe deficit writes: \\[\nD_t = \\text{PET}_t - \\text{AET}_t.\n\\]\n\n\n\n\n\n\nHow to compute water input \\(W_t\\) with daily data?\n\n\n\n\n\nDaily snowmelt is often estimated using a degree-day approach, which assumes that melt is proportional to the number of degrees by which air temperature exceeds a threshold (typically 0°C). This formulation applies only to the existing snowpack, ensuring that snow deposited on a given day cannot melt immediately.\nFollowing the standard degree-day formulation (Dingman (2015), Eq. 5.71), the daily snowmelt is written as a linear function of air temperature: \\[\n\\text{Melt}_t = \\min\\left\\{\\text{DDF} \\times \\max(\\mathrm{Tmean}_t - T_0,\\, 0),\\, \\text{Pack}_{t-1}\\right\\}\n\\tag{5.9}\\]\nwhere \\(\\text{DDF}\\) is the degree-day factor (mm day\\(^{-1}\\)°C\\(^{-1}\\)), typically in the range 2–5 mm day\\(^{-1}\\)°C\\(^{-1}\\) depending on snow properties and surface conditions. The parameter \\(T_0\\) is the threshold temperature for melting (which is always set as 0°C). \\(\\mathrm{Tmean}_t\\) is the daily mean air temperature (see Equation 5.13). \\(\\text{Pack}_{t-1}\\) is the snow water equivalent remaining from the previous day.\nThe snowpack evolves according to the mass balance: \\[\n\\text{Pack}_t = \\text{Pack}_{t-1} + \\text{Snow}_t - \\text{Melt}_t.\n\\]\nThe snow pack equation is recursive. We simply set the start value at 0 for the first date of the sequence of values within a cell.\n\\(\\text{Snow}_t\\) is the amount of snow, which is the amount of precipitation if the average daily temperature is lower or equal to \\(T_0\\), and 0 otherwise: \\[\n\\text{Snow}_t = \\begin{cases}\nP_t, & \\text{if } T_{\\text{mean}_t} \\leq T_0 \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\tag{5.10}\\]\nConversely, the amount of rain is defined as: \\[\n\\text{Rain}_t = \\begin{cases}\nP_t, & \\text{if } T_{\\text{mean}_t} &gt; T_0 \\\\\n0, & \\text{otherwise}.\n\\end{cases}\n\\tag{5.11}\\]\nThe total water input to the soil becomes: \\[\nW_t = \\text{Rain}_t + \\text{Melt}_t.\n\\]\n\n\n\n\n\n\n\n\n\nHow to compute water input \\(W_t\\) with monthly data?\n\n\n\n\n\nMelt Factor and Rain/Snow Partition\nThe monthly precipitation can be divided into a rain fraction \\(\\text{Rain}_t\\) and a snow fraction \\(\\text{Snow}_t\\). To do so, we define the melt factor \\(F_t\\): \\[\nF_t = \\begin{cases}\n0, & \\text{if }\\text{Tmean}_t \\leq 0^\\circ,\\\\\n0.167 \\times \\text{Tmean}_t, & \\text{if } 0^\\circ &lt;\\text{Tmean}_t \\leq 6^\\circ,\\\\\n0, & \\text{if }\\text{Tmean}_t &gt; 6^\\circ.\n\\end{cases}\n\\tag{5.12}\\]\nwhere \\(\\text{Tmean}_t\\) is the daily average temperature: \\[\n\\mathrm{Tmean}_t = \\frac{\\mathrm{Tmin}_t + \\mathrm{Tmax}_t}{2}.\n\\tag{5.13}\\]\nThe rain and snow fractions can then be computed as follows: \\[\n\\begin{align}\n\\text{Rain}_t & = F_t \\times P_t\\\\\n\\text{Snow}_t & = (1 - F_t) \\times P_t\n\\end{align}\n\\tag{5.14}\\]\nRecursive Snowpack and Melt\nThe melt factor \\(F_t\\) is also used to define snowmelt \\(\\text{Melt}_t\\): \\[\n\\text{Melt}_t = F_t \\times (\\text{Snow}_t + \\text{Pack}_{t-1}),\n\\tag{5.15}\\]\nwhere snow pack for a given day is given by: \\[\n\\text{Pack}_t = (1 - F_t)^2 \\times P_t + (1 - F_t) \\times \\text{Pack}_{t-1}\n\\tag{5.16}\\]\nThe snow pack equation is recursive. We simply set the start value at 0 for the first date of the sequence of values within a cell.\nThe monthly water input to the soil is obtained as: \\[\nW_t = \\text{Rain}_t + \\text{Melt}_t\n\\tag{5.17}\\]\n\n\n\nLet us first compute water deficit \\(W_t\\).\n\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  mutate(\n    T0 = 0,# freezing temperature\n    rain  = if_else(temp_mean &gt; T0, precip, 0),\n    snow  = if_else(temp_mean &lt;= T0, precip, 0),\n    # Degree-day melt from existing pack only\n    DDF = 3, # mm/day/°C\n    pot_melt = pmax(temp_mean - T0, 0) * DDF\n  ) |&gt; \n  arrange(cell_id, date) |&gt; \n  group_by(cell_id) |&gt;\n  # Daily snowpack recursion and melt\n  mutate(\n    pack = {\n      n &lt;- n()\n      out &lt;- numeric(n); prev &lt;- 0\n      for (i in seq_len(n)) {\n        melt_i &lt;- min(pot_melt[i], prev)# melt from previous pack only\n        out[i] &lt;- prev + snow[i] - melt_i\n        prev &lt;- out[i]\n      }\n      out\n    },\n    melt = pmin(lag(pack, default = 0), pot_melt),\n    water_input = rain + melt\n  ) |&gt; \n  ungroup() |&gt;\n  select(-DDF, -T0, -pot_melt)\n\n\n\nCode if monthly data and not daily\n# This code is not evaluated here since we use daily data\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt; \n  mutate(\n    # Monthly melt factor and rain/snow split\n    melt_factor = case_when(\n      temp_mean &lt;= 0 ~ 0,\n      temp_mean &gt;= 6 ~ 1,\n      TRUE           ~ 0.167 * temp_mean\n    ),\n    rain = melt_factor * precip,\n    snow = (1 - melt_factor) * precip\n  ) |&gt; \n  arrange(cell_id, date) |&gt; \n  group_by(cell_id) |&gt;\n  # Monthly snowpack recursion and melt\n  mutate(\n    a = 1 - melt_factor,\n    b = (a^2) * precip, # term added each day\n    c = a, # multiplier on previous pack\n    pack = {\n      init &lt;- 0 # initial PACK for this cell_id\n      # pack_t = b_t + c_t * pack_{t-1}\n      out &lt;- purrr:::accumulate2(\n        b, c,\n        .init = init,\n        .f = function(bi, ci, prev) bi + ci * prev\n      )\n      as.numeric(tail(out, -1)) # drop the initial value\n    },\n    pack_lag = lag(pack, default = 0),\n    melt = melt_factor * (snow + pack_lag),\n    water_input = rain + melt\n  ) |&gt;\n  ungroup() |&gt;\n  select(-a, -b, -c)\n\n\nThen, we can compute soil water balance (\\(\\text{SW}_t\\)), actual evapotranspiration (\\(\\text{AET}_t\\)) and soil water deficit \\(D_t\\).\nWe define the update_soil_water_deficit() function that computes those values for a subset of observation corresponding to a cell, using the following input variables: \\(W_t\\), \\(\\text{PET}_t\\), \\(\\text{SW}_{t-1}\\) and \\(S_{\\text{max}}\\).\n\n\nThe update_soil_water_deficit() function.\n#' Compute Soil Water Deficit\n#' \n#' @param W Water input to the system (in mm).\n#' @param PET Potential evapotranspiration (in mm).\n#' @param S_prev Soil water balance in previous period (in mm).\n#' @param S_max Soil water-holding capacity in the top 200cm of the soil \n#'  profile (in mm).\n#' \n#' @returns A list with the following elements:\n#'  - `S_new`: soil water balance,\n#'  - `AET`: evapotranspiration,\n#'  - `surplus`: water surplus,\n#'  - `deficit`: water deficit\n#'  \nupdate_soil_water_deficit &lt;- function(W, PET, S_prev, S_max) {\n  \n  if (W &gt;= PET) {\n    # Water-abundant day: recharge first, overflow = surplus\n    S_star &lt;- (W - PET) + S_prev\n    # New value for soil water balance\n    S_new &lt;- min(S_star, S_max)\n    \n    AET &lt;- PET # Evapotranspiration\n    surplus &lt;- max(0, S_star - S_max)\n    deficit &lt;- 0\n  } else {\n    # Water-limited day: exponential draw from storage (Dingman/Lutz Eq. 13)\n    D &lt;- PET - W # unmet demand by inputs\n    dSOIL &lt;- S_prev * (1 - exp(-D / S_max))  # fraction removed from storage\n    # New value for soil water balance\n    S_new &lt;- S_prev - dSOIL\n    \n    AET &lt;- W + dSOIL # Evapotranspiration\n    surplus &lt;- 0\n    deficit &lt;- PET - AET\n  }\n  \n  list(\n    S_new = S_new, # Soil water balance\n    AET = AET, # Evapotranspiration\n    surplus = surplus, # Water surplus\n    deficit = deficit # Water deficit\n  )\n}\n\n\nWe use that function on subsets of the dataset where each subset corresponds to a cell.\n\n# Note: this chunk takes about 3 minutes to run.\n# It is not evaluated here during compilation.\nif (!file.exists(\"NZL_temprary_water_deficit.rda\")) {\n  # Ideally, we would need to use a value at the cell level.\n  Smax_default &lt;- 150\n  \n  country_weather_daily &lt;- \n    country_weather_daily |&gt;\n    arrange(cell_id, date) |&gt;\n    group_by(cell_id) |&gt;\n    # Prepare new columns\n    mutate(\n      AET = NA_real_, # Evapostranspiration\n      soil_moisture = NA_real_, # Water storage\n      soil_surplus = NA_real_, # Water surplus\n      soil_deficit = NA_real_ # Water deficit\n    ) |&gt;\n    # For each cell, compute soil water deficit recursively\n    group_modify(\\(tb, key){\n      n &lt;- nrow(tb)\n      S  &lt;- 0.5 * Smax_default\n      for (i in seq_len(n)) {\n        u &lt;- update_soil_water_deficit(\n          W = tb$water_input[i],\n          PET = tb$PET_daily[i],\n          S_prev = S,\n          S_max = Smax_default\n        )\n        tb$AET[i] &lt;- u$AET\n        tb$soil_moisture[i] &lt;- u$S_new\n        tb$soil_surplus[i] &lt;- u$surplus\n        tb$soil_deficit[i] &lt;- u$deficit\n        S &lt;- u$S_new\n      }\n      tb\n    }) |&gt;\n    ungroup()\n  \n  save(\n    country_weather_daily, \n    file = \"NZL_temprary_water_deficit.rda\"\n  )\n} else {\n  load(\"NZL_temprary_water_deficit.rda\")\n}\n\ncountry_weather_daily\n\n# A tibble: 2,975,097 × 25\n   cell_id longitude latitude country_code date        precip temp_min temp_max\n     &lt;int&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;        &lt;date&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1       9      166.    -45.8 NZL          1980-01-01 19.5        5.38     18.1\n 2       9      166.    -45.8 NZL          1980-01-02  6.58      10.7      12.3\n 3       9      166.    -45.8 NZL          1980-01-03  2.47       9.22     13.6\n 4       9      166.    -45.8 NZL          1980-01-04  0          6.35     18.1\n 5       9      166.    -45.8 NZL          1980-01-05  0          6.42     19.2\n 6       9      166.    -45.8 NZL          1980-01-06  0          8.80     19.1\n 7       9      166.    -45.8 NZL          1980-01-07  0.0987    12.0      18.2\n 8       9      166.    -45.8 NZL          1980-01-08  0.105     11.0      14.6\n 9       9      166.    -45.8 NZL          1980-01-09  0          5.38     16.0\n10       9      166.    -45.8 NZL          1980-01-10  0          7.00     17.8\n# ℹ 2,975,087 more rows\n# ℹ 17 more variables: year &lt;dbl&gt;, month &lt;dbl&gt;, month_name &lt;ord&gt;,\n#   day_of_year &lt;dbl&gt;, temp_mean &lt;dbl&gt;, dl_hours &lt;dbl&gt;, esat &lt;dbl&gt;,\n#   PET_daily &lt;dbl&gt;, rain &lt;dbl&gt;, snow &lt;dbl&gt;, pack &lt;dbl&gt;, melt &lt;dbl&gt;,\n#   water_input &lt;dbl&gt;, AET &lt;dbl&gt;, soil_moisture &lt;dbl&gt;, soil_surplus &lt;dbl&gt;,\n#   soil_deficit &lt;dbl&gt;",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html#soil-moisture-deficit-index-smdi",
    "href": "data-weather-metrics.html#soil-moisture-deficit-index-smdi",
    "title": "5  Weather Data: Metrics",
    "section": "5.3 Soil Moisture Deficit Index (SMDI)",
    "text": "5.3 Soil Moisture Deficit Index (SMDI)\nThe Soil Moisture Deficit Index (SMDI, see Narasimhan and Srinivasan (2005)), turns daily soil water storage into a weekly drought/wetness index which takes values on \\([-4,4]\\) and which is comparable across locations and seasons. Negative values indicate dry conditions whereas positive values indicate wet conditions.\nSince we have daily observation, we need to compute weekly values for soil moisture. We assign each day to one of 52 fixed 7-day blocks starting on January 1: \\[\n\\text{week} = \\min\\left(\\left\\lfloor\\frac{\\text{yday}-1}{7}\\right\\rfloor + 1,\\ 52\\right).\n\\] Note that we do not use the week() function from {lubridate} to avoid ISO weeks (which can have 53).\nThen, for each grid cell (i), year (y), and week (w), compute the weekly mean available soil water: \\[\n\\mathrm{SW}_{i,y,w} = \\frac{1}{n_{i,y,w}} \\sum_{t \\in (i,y,w)} \\text{SW}_t,\n\\tag{5.18}\\]\nwhere \\(\\text{SW}_t\\) is the soil water balance (in mm), previously computed (see Equation 5.7).\nWe define a function, find_wday() which assigns a fixed 7-day “week” indice (1 to 52) to calendar dates.\n\n#' Assign fixed 7-day \"week\" indices (1–52) to calendar dates\n#'\n#' @description\n#' Divides each year into 52 fixed 7-day blocks, starting on January 1\n#' (block 1 = days 1–7, block 2 = days 8–14, ...\n#' Any remaining day(s) beyond day 364 (e.g., Dec 31 in common years,\n#' or Dec 30–31 in leap years) are assigned to week 52.\n#'\n#' @param x A `Date` vector.\n#' @returns\n#' An integer vector of the same length as `x`, giving week indices in `1:52`.\n#' \nfind_wday &lt;- function(x) {\n  pmin(((yday(x) - 1) %/% 7) + 1, 52)\n}\n\nExample:\n\nfind_wday(c(make_date(2020,12,31), make_date(2021,01,01)))\n\n[1] 52  1\n\n\n\n# First assign each day to one of the 52 weeks\ncountry_weather_daily &lt;- \n  country_weather_daily |&gt;\n  mutate(\n    # week = lubridate::week(date) # includes 53...\n    week = find_wday(date)\n  )\n\n# Then compute the average availabe soil water at the cell level\nsw_weekly &lt;- \n  country_weather_daily |&gt; \n  group_by(cell_id, year, week) |&gt;\n  summarise(SW = mean(soil_moisture, na.rm = TRUE), .groups = \"drop\")\n\nThe long-term weekly statistics at the cell level then need to be computed:\n\n\\(\\text{MSW}_{i,w}\\): the median of \\(\\text{SW}_{i,y,w}\\) over a long period (the entire sample, here),\n\\(\\text{SW}_{\\text{min},i,w}\\): the min of \\(\\text{SW}_{i,y,w}\\) over the same long period.\n\\(\\text{SW}_{\\text{max},i,w}\\): the max of \\(\\text{SW}_{i,y,w}\\) over the same long period.\n\n\n# Long-term weekly statistics\nsw_lt &lt;- \n  sw_weekly |&gt;\n  group_by(cell_id, week) |&gt;\n  summarise(\n    MSW = median(SW, na.rm = TRUE),\n    SW_min = min(SW, na.rm = TRUE),\n    SW_max = max(SW, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\nThe weekly soil-water anomaly are then computed, in percent. For each (cell, year, week), a piecewise, range-normalized anomaly is computed as follows: \\[\n\\text{SD}_{i,y,w} =\n\\begin{cases}\n100 \\dfrac{\\text{SW}_{i,y,w} - \\text{MSW}_{i,w}}{\\text{MSW}_{i,w}-\\text{SW}_{\\min,i,w}}, & \\text{if } \\text{SW}_{i,y,w} \\le \\text{MSW}_{i,w},\\\\\n100 \\dfrac{\\text{SW}_{i,y,w} - \\text{MSW}_{i,w}}{\\text{SW}_{\\max,i,w}-\\mathrm{MSW}_{i,w}}, & \\text{otherwise}\n\\end{cases}\n\\tag{5.19}\\]\nWeekly soil water anomalies \\(\\text{SD}_{i,y,w}\\) will be negative when they are drier than the median for that week, positive when wetter, and naturally scaled by the local weekly climatological range.\n\n# Soil water deficit (%)\nsw_anom &lt;- \n  sw_weekly |&gt;\n  left_join(sw_lt, by = c(\"cell_id\", \"week\")) |&gt;\n  mutate(\n    SD = if_else(\n      SW &lt;= MSW,\n      100 * (SW - MSW) / pmax(MSW - SW_min, 1e-9),\n      100 * (SW - MSW) / pmax(SW_max - MSW, 1e-9)\n    )\n  )\n\nYou may have notice that in the previous code, the denominator is ‘protected’ with a tiny value (\\(10^{-9}\\)) to avoid division by zero in flat climates.\nThe last step consists in computing the SMDI in a recursive manner: the SMDI carries persistence via a first-order recursion within each calendar year: \\[\n\\begin{align*}\n\\text{SMDI}_{i,y,1} & = \\frac{\\text{SD}_{i,y,1}}{50},\\\\\n\\text{SMDI}_{i,y,w} & = 0.5,\\text{SMDI}_{i,y,w-1} + \\frac{\\text{SD}_{i,y,w}}{50}\\quad (w\\ge 2).\n\\end{align*}\n\\tag{5.20}\\]\n\n# SMDI computed recursively, by cell.\nsmdi_weekly &lt;- \n  sw_anom |&gt;\n  arrange(cell_id, year, week) |&gt;\n  group_by(cell_id, year) |&gt;\n  group_modify(\\(tb, key) {\n    n &lt;- nrow(tb)\n    smdi &lt;- numeric(n)\n    for (i in seq_len(n)) {\n      if (i == 1 || is.na(smdi[i-1])) {\n        # Initial value\n        smdi[i] &lt;- tb$SD[i] / 50\n      } else {\n        smdi[i] &lt;- 0.5 * smdi[i-1] + tb$SD[i] / 50\n      }\n    }\n    tb$SMDI &lt;- smdi\n    tb\n  }) |&gt;\n  ungroup()\n\nLet us have a look at the values for a cell:\n\nggplot(\n data = smdi_weekly |&gt; filter(cell_id == 19) |&gt; mutate(x = year + week/52),\n mapping = aes(x = x, y = SMDI)\n) +\n  geom_line() +\n  labs(x = NULL)\n\n\n\n\nFigure 5.1: SMDI for a cell in New Zealand. Weekly values range from -4 to +4 indicating very dry to very wet conditions.\n\n\n\n\n\n\n\n\n\n5.3.1 Monthly Aggregation\nThe SMDI values are computed on a weekly basis (52 fixed 7-day blocks per year). To align with standard reporting periods of macroeconomic data, we can aggregate these values to the monthly scale. Because some 7-day weeks span two months, we need to ensure that each month receives only the appropriate share of each week.\nWe proceed as follows:\n\nWe build a monthly calendar of overlaps. For every combination of year and month present in the data, we compute how many days of each fixed 7-day week fall within that month. This gives us a set of weights (\\(w^{(m)}_{w}\\)) that indicate the fraction of the month covered by each week. The weights for a given month always sum to 1.\nWe compute weighted monthly SMDI values. We join the weights from the previous step with the weekly SMDI observations and compute, for each grid cell, year, and month, a weighted mean of weekly SMDI values: \\[\n\\mathrm{SMDI}_{m} = \\frac{\\sum_{w} \\mathrm{SMDI}_{w} \\times w^{(m)}_{w}}{\\sum_{w} w^{(m)}_{w}},\n  \\] where (\\(w^{(m)}_{w}\\)) is the proportion of the month accounted for by week (w).\n\nWe define a function, get_month_week_cal(), to get a monthly calendar of overlaps. Note that it relies on the find_wday() function previously defined.\n\n#' Calendar of fixed 7-day \"weeks\" (1--52) overlapped with a given month\n#'\n#' @description\n#' Builds the 52 fixed 7-day blocks for a given year\n#' (block 1 starts on Jan 1, block k starts on Jan 1 + 7*(k-1) days),\n#' computes each block's overlap (in days) with the specified month,\n#' and returns per-block weights equal to overlap / days-in-month.' \n#' \n#' @param year Year (numeric).\n#' @param month Month (numeric).\n#' \n#' @returns\n#' A tibble with one row per overlapping block and columns:\n#' - `year`: the requested year,\n#' - `month`: the requested month,\n#' - `week`: fixed 7-day block index in 1...52,\n#' - `weight_ndays`: overlap days over days in the month.\n#' \nget_month_week_cal &lt;- function(year, month) {\n  \n  m_start &lt;- lubridate::make_date(year, month, 1)\n  m_end &lt;- (m_start %m+% months(1)) - lubridate::days(1)\n  # days in the month\n  dates &lt;- seq(lubridate::ymd(m_start), lubridate::ymd(m_end), by = \"day\")\n  weeks &lt;- sapply(dates, find_wday)\n  ndays_weeks &lt;- tapply(weeks, weeks, length)\n  \n  dplyr::tibble(\n    week = as.integer(names(ndays_weeks)),\n    nb_days = as.integer(ndays_weeks),\n    weight_ndays = nb_days / sum(nb_days)\n  ) |&gt; \n    dplyr::mutate(\n      year = year,\n      month = month,\n      .before = 1L\n    )\n}\n\nFor example:\n\nget_month_week_cal(2020, 12)\n\n# A tibble: 5 × 5\n   year month  week nb_days weight_ndays\n  &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;   &lt;int&gt;        &lt;dbl&gt;\n1  2020    12    48       1       0.0323\n2  2020    12    49       7       0.226 \n3  2020    12    50       7       0.226 \n4  2020    12    51       7       0.226 \n5  2020    12    52       9       0.290 \n\n\nThe years in the data:\n\nyears &lt;- sort(unique(smdi_weekly$year))\n\nWe get the calendar of months for monthly aggregations by applying the get_month_week_cal() function to all the (year, month) covering the sample period:\n\nmonths_cal &lt;- tidyr::crossing(year = years, month = 1:12) |&gt;\n  purrr::pmap(\\(year, month) get_month_week_cal(year, month)) |&gt; \n  list_rbind()\nmonths_cal\n\n# A tibble: 2,778 × 5\n    year month  week nb_days weight_ndays\n   &lt;dbl&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;        &lt;dbl&gt;\n 1  1980     1     1       7       0.226 \n 2  1980     1     2       7       0.226 \n 3  1980     1     3       7       0.226 \n 4  1980     1     4       7       0.226 \n 5  1980     1     5       3       0.0968\n 6  1980     2     5       4       0.138 \n 7  1980     2     6       7       0.241 \n 8  1980     2     7       7       0.241 \n 9  1980     2     8       7       0.241 \n10  1980     2     9       4       0.138 \n# ℹ 2,768 more rows\n\n\nWe then proceed to the second step, where we compute the monthly aggregated values for SMDI:\n\nsmdi_monthly &lt;- \n  smdi_weekly |&gt; \n  left_join(\n    months_cal, by = c(\"year\", \"week\"),\n    relationship = \"many-to-many\"\n  ) |&gt; \n  group_by(cell_id, year, month) |&gt;\n  summarise(\n    # If any missing values in SMDI will lead to NAs\n    SMDI_month = weighted.mean(SMDI, w = weight_ndays),\n    .groups = \"drop\"\n  )\n\nLet us have a look at the values for a cell:\n\nggplot(\n  data = smdi_monthly |&gt; mutate(date = year + month / 12) |&gt; \n    filter(cell_id == 19),\n  mapping = aes(x = date, y = SMDI_month)\n  ) +\n  geom_line() +\n  labs(x = NULL, y = \"SMDI\")\n\n\n\n\nFigure 5.2: Monthly SMDI values for a cell in New Zealand. Weekly values range from -4 to +4 indicating very dry to very wet conditions.\n\n\n\n\n\n\n\n\n\n\n5.3.2 Quarterly Aggregation\nWe may want to aggregate the SMDI values at the quarterly level (Q1–Q4). We follow the same logic as for monthly aggregation, adapting it to quarters:\n\nWe first build a quarterly calendar of overlaps. For each year and quarter, we determine how many days of each 7-day week fall within the quarter. This yields a set of weights (\\(w^{(q)}_w\\)) expressing the fraction of the quarter represented by each week. The weights for a given quarter always sum to 1.\nWe then compute weighted quarterly SMDI values. Using these weights, we aggregate the weekly SMDI values within each quarter by taking a weighted average, where each week’s contribution is proportional to the number of days it contributes to that quarter: \\[\n\\mathrm{SMDI}_{q} = \\frac{\\sum_{w} \\mathrm{SMDI}_{w} \\times w^{(q)}_{w}}{\\sum_{w} w^{(q)}_{w}},\n\\] where (\\(w^{(q)}_{w}\\)) denotes the proportion of the quarter accounted for by week (w).\n\nThe get_quarter_week_cal() function creates the quarterly calendar of overlaps. Again, note that it relies on the find_wday() function previously defined.\n\n#' Calendar weights for fixed 7-day \"weeks\" (1–52) within a given quarter\n#'\n#' @description\n#' For a given `year` and `quarter`, this function computes the number of days\n#' from each fixed 7-day block (weeks 1–52, defined from January 1 in 7-day\n#' increments) that fall within that quarter, along with their normalized\n#' weights. Any remaining days beyond day 364 (e.g., Dec 31 in common years,\n#' or Dec 30–31 in leap years) are assigned to week 52.\n#' \n#' @param year Year (numeric).\n#' @param quarter Quarter (numeric).\n#' \n#' @returns\n#' A tibble with one row per overlapping block and columns:\n#' - `year`: the requested year,\n#' - `quarter`: the requested quarter,\n#' - `week`: fixed 7-day block index in 1...52,\n#' - `weight_ndays`: overlap days over days in the quarter.\n#' \nget_quarter_week_cal &lt;- function(year, quarter) {\n  q_start &lt;- lubridate::make_date(year, (quarter - 1) * 3 + 1, 1)\n  q_end &lt;- (q_start %m+% months(3)) - lubridate::days(1)\n  dates &lt;- seq(q_start, q_end, by = \"day\")\n  weeks &lt;- find_wday(dates)\n  ndays_quarter &lt;- tapply(weeks, weeks, length)\n  \n  dplyr::tibble(\n    week = as.integer(names(ndays_quarter)),\n    nb_days = as.integer(ndays_quarter),\n    weight_ndays = nb_days / sum(nb_days)\n  ) |&gt; \n    dplyr::mutate(\n      year = year,\n      quarter = quarter,\n      .before = 1L\n    )\n}\n\nThe calendar of months for monthly aggregations:\n\nquarters_cal &lt;- tidyr::crossing(year = years, quarter = 1:4) |&gt;\n  purrr::pmap(\\(year, quarter) get_quarter_week_cal(year, quarter)) |&gt; \n  list_rbind()\nquarters_cal\n\n# A tibble: 2,418 × 5\n    year quarter  week nb_days weight_ndays\n   &lt;dbl&gt;   &lt;int&gt; &lt;int&gt;   &lt;int&gt;        &lt;dbl&gt;\n 1  1980       1     1       7       0.0769\n 2  1980       1     2       7       0.0769\n 3  1980       1     3       7       0.0769\n 4  1980       1     4       7       0.0769\n 5  1980       1     5       7       0.0769\n 6  1980       1     6       7       0.0769\n 7  1980       1     7       7       0.0769\n 8  1980       1     8       7       0.0769\n 9  1980       1     9       7       0.0769\n10  1980       1    10       7       0.0769\n# ℹ 2,408 more rows\n\n\nWe then proceed to the second step, where we compute the quarterly aggregated values for SMDI:\n\nsmdi_quarterly &lt;- \n  smdi_weekly |&gt; \n  left_join(\n    quarters_cal, by = c(\"year\", \"week\"),\n    relationship = \"many-to-many\"\n  ) |&gt; \n  group_by(cell_id, year, quarter) |&gt;\n  summarise(\n    # If any missing values in SMDI will lead to NAs\n    SMDI_quarter = weighted.mean(SMDI, w = weight_ndays),\n    .groups = \"drop\"\n  )\n\nLet us have a look at the values for a cell:\n\nggplot(\n  data = smdi_quarterly |&gt; mutate(date = year + quarter / 4) |&gt; \n    filter(cell_id == 19),\n  mapping = aes(x = date, y = SMDI_quarter)\n  ) +\n  geom_line() +\n  labs(x = NULL, y = \"SMDI\")\n\n\n\n\nFigure 5.3: Quarterly SMDI values for a cell in New Zealand. Quarterly values range from -4 to +4 indicating very dry to very wet conditions.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html#sec-spei",
    "href": "data-weather-metrics.html#sec-spei",
    "title": "5  Weather Data: Metrics",
    "section": "5.4 SPEI",
    "text": "5.4 SPEI\nWe will compute the Standardized Precipitation-Evapotranspiration Index (SPEI), a versatile drought index that uses climatic data to assess the onset, duration, and severity of drought conditions compared to normal conditions Vicente-Serrano, Beguería, and López-Moreno (2010). The SPEI index relies on the precipitation levels and potential evapotranspiration (estimated in Section 5.1).\nThe SPEI requires:\n\nMonthly precipitation \\(P_m\\) and monthly potential evapotranspiration \\(\\text{PET}_m\\) as inputs,\nWater balance: \\(D_m = P_m - \\text{PET}_m\\),\nA scale \\(k\\), usually in \\(\\{1,2,3,6,12,24\\}\\), which defines the width (in months) for rolling accumulations. This scale thus controls for the magnitude of the memory,\nA calibration window (we will use 1981–2010).\n\nFirst, we need to compute monthly aggregation of required weather variables, at the grid cell level.\n\nweather_monthly &lt;- \n  country_weather_daily |&gt; \n  mutate(ym = floor_date(date, \"month\")) |&gt; \n  group_by(cell_id, ym, year, month) |&gt; \n  summarise(\n    P = sum(precip, na.rm = TRUE), # in mm/month\n    PET = sum(PET_daily, na.rm = TRUE), # in mm/month\n    .groups = \"drop\"\n  ) |&gt; \n  arrange(cell_id, year, month) |&gt; \n  mutate(balance = P - PET)\n  \nweather_monthly\n\n# A tibble: 97,740 × 7\n   cell_id ym          year month     P   PET balance\n     &lt;int&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1       9 1980-01-01  1980     1 213.   77.9   135. \n 2       9 1980-02-01  1980     2 160.   66.3    93.9\n 3       9 1980-03-01  1980     3 152.   56.7    95.8\n 4       9 1980-04-01  1980     4  69.0  41.5    27.6\n 5       9 1980-05-01  1980     5 202.   35.0   168. \n 6       9 1980-06-01  1980     6 165.   25.4   139. \n 7       9 1980-07-01  1980     7 166.   26.5   139. \n 8       9 1980-08-01  1980     8 182.   33.3   149. \n 9       9 1980-09-01  1980     9 183.   41.1   142. \n10       9 1980-10-01  1980    10 129.   55.0    73.5\n# ℹ 97,730 more rows\n\n\nIn construction\n\n# Computes SPEI for a single grid cell\ncompute_spei &lt;- function(df, \n                         scales = c(1, 3, 6, 12),\n                         ref_start = NULL, \n                         ref_end = NULL) {\n  \n  # Build a ts object for water balance with frequency = 12\n  start_year  &lt;- min(df$year, na.rm = TRUE)\n  start_month &lt;- month(min(df$ym, na.rm = TRUE))\n  bal_ts &lt;- ts(df$balance, start = c(start_year, start_month), frequency = 12)\n  \n  # Run SPEI for each scale\n  spei_list &lt;- lapply(scales, function(k) {\n    if (is.null(ref_start) || is.null(ref_end)) {\n      fit &lt;- SPEI::spei(bal_ts, scale = k, verbose = FALSE)\n    } else {\n      fit &lt;- SPEI::spei(\n        bal_ts, scale = k, \n        ref.start = ref_start, ref.end = ref_end,\n        verbose = FALSE\n      )\n    }\n    # Extract the fitted standardized values as a numeric vector\n    spei_values &lt;- as.numeric(fit$fitted)\n    tibble(\n      ym = df$ym, \n      scale = k,\n      !!paste(\"SPEI\", k, sep = \"_\") := spei_values\n    )\n  })\n  bind_cols(spei_list)\n}\n\n\nref_start &lt;- c(1981, 1)\nref_end &lt;- c(2010, 12)\n\n\ndf &lt;- weather_monthly %&gt;%\n  filter(cell_id == 19)",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "data-weather-metrics.html#monthly-aggregation-1",
    "href": "data-weather-metrics.html#monthly-aggregation-1",
    "title": "5  Weather Data: Metrics",
    "section": "5.5 Monthly Aggregation",
    "text": "5.5 Monthly Aggregation\n\ncountry_weather_monthly &lt;- \n  country_weather_daily |&gt; \n  group_by(\n    cell_id, longitude, latitude, country_code, \n    year, month, month_name\n  ) |&gt; \n  summarise(\n    precip = sum(precip, na.rm = TRUE), # mm/month\n    temp_min = mean(temp_min, na.rm = TRUE),\n    temp_max = mean(temp_max, na.rm = TRUE),\n    temp_mean = mean(temp_mean,   na.rm = TRUE),\n    PET = sum(PET_daily, na.rm = TRUE), # mm/month\n    .groups = \"drop\"\n  )\n\n\n\n\n\nCampbell, Gaylon S., and John M. Norman. 1998. “Introduction.” In An Introduction to Environmental Biophysics, 1–13. Springer New York. https://doi.org/10.1007/978-1-4612-1626-1_1.\n\n\nDingman, S. Lawrence. 2015. Physical Hydrology. Waveland press.\n\n\nHamon, W. R. 1964. “Computation of Direct Runoff Amounts from Storm Rainfall” 63: 52–62.\n\n\nLutz, James A., Jan W. van Wagtendonk, and Jerry F. Franklin. 2010. “Climatic Water Deficit, Tree Species Ranges, and Climate Change in Yosemite National Park.” Journal of Biogeography 37 (5): 936–50. https://doi.org/10.1111/j.1365-2699.2009.02268.x.\n\n\nNarasimhan, B., and R. Srinivasan. 2005. “Development and Evaluation of Soil Moisture Deficit Index (SMDI) and Evapotranspiration Deficit Index (ETDI) for Agricultural Drought Monitoring.” Agricultural and Forest Meteorology 133 (1–4): 69–88. https://doi.org/10.1016/j.agrformet.2005.07.012.\n\n\nVicente-Serrano, Sergio M., Santiago Beguería, and Juan I. López-Moreno. 2010. “A Multiscalar Drought Index Sensitive to Global Warming: The Standardized Precipitation Evapotranspiration Index.” Journal of Climate 23 (7): 1696–1718. https://doi.org/10.1175/2009jcli2909.1.",
    "crumbs": [
      "Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Weather Data: Metrics</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Campbell, Gaylon S., and John M. Norman. 1998.\n“Introduction.” In An Introduction to Environmental\nBiophysics, 1–13. Springer New York. https://doi.org/10.1007/978-1-4612-1626-1_1.\n\n\nDingman, S. Lawrence. 2015. Physical Hydrology. Waveland press.\n\n\nHamon, W. R. 1964. “Computation of Direct Runoff Amounts from\nStorm Rainfall” 63: 52–62.\n\n\nLutz, James A., Jan W. van Wagtendonk, and Jerry F. Franklin. 2010.\n“Climatic Water Deficit, Tree Species Ranges, and Climate Change\nin Yosemite National Park.” Journal of Biogeography 37\n(5): 936–50. https://doi.org/10.1111/j.1365-2699.2009.02268.x.\n\n\nNarasimhan, B., and R. Srinivasan. 2005. “Development and\nEvaluation of Soil Moisture Deficit Index (SMDI) and Evapotranspiration\nDeficit Index (ETDI) for Agricultural Drought Monitoring.”\nAgricultural and Forest Meteorology 133 (1–4): 69–88. https://doi.org/10.1016/j.agrformet.2005.07.012.\n\n\nVicente-Serrano, Sergio M., Santiago Beguería, and Juan I. López-Moreno.\n2010. “A Multiscalar Drought Index Sensitive to Global Warming:\nThe Standardized Precipitation Evapotranspiration Index.”\nJournal of Climate 23 (7): 1696–1718. https://doi.org/10.1175/2009jcli2909.1.",
    "crumbs": [
      "References"
    ]
  }
]